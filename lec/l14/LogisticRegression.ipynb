{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 17: Logistic Regression\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall classification problem notation:\n",
    "\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email\n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=-1$: not spam\n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training data:**\n",
    "\n",
    "We are given training data $D = \\{(\\vec{x}_1, y_1), \\ldots, (\\vec{x}_n, y_n)\\}$\n",
    "\n",
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n",
    "\n",
    "How to classify a new instance?  \n",
    " \"free money\" -> $\\{1,1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall Naive Bayes:**\n",
    "\n",
    "$p(y|\\vec{x}) = \\frac{p(\\vec{x}|y)p(y)}{p(\\vec{x})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recall gradient descent recipe **\n",
    "\n",
    "1.  Select a model type (e.g., linear classification, logistic classification)\n",
    "\n",
    "2.  Select an <span>**error function**</span> that, when minimized, results in a good setting of the model parameters.\n",
    "\n",
    "3.  Analytically determine the gradient of the error function with respect to the model parameters.\n",
    "\n",
    "4.  Iteratively change the parameters by a small amount in the direction of the gradient until the (near) minimum of the error function is found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we considered a simple linear model with two parameters:\n",
    "\n",
    "$h(x_i) = mx_i + b$\n",
    "\n",
    "This assumes only a single feature (term). \n",
    "\n",
    "Instead, we make $x_i$ a vector $\\vec{x_i}$ containing values for $v$ terms: $\\vec{x_i} = \\{x_{i1} \\ldots x_{iv}\\}$, which has a corresponding vector of parameters $\\vec{\\theta}$.\n",
    "\n",
    "$$ h(\\vec{x}_i) = \\vec{x}_i^T  {\\theta} = x_{i1} \\theta_1 + \\ldots x_{iv} \\theta_v = \\sum_j x_{ij}{\\theta}_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array as npa\n",
    "import numpy as np\n",
    "\n",
    "def h(x, theta):\n",
    "    return np.dot(x.T, theta)\n",
    "\n",
    "x = npa([1,2,3])  # term0 appears 1 time, term1 appears 2 times...\n",
    "theta = npa([-1, -1, 5])  # term 2 predictive of positive class\n",
    "h(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a negative example.\n",
    "x2 = npa([10, 10, 0])\n",
    "h(x2, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given training data $D$, how do we pick $\\vec{\\theta}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the gradient descent recipe, we need an error function:\n",
    "\n",
    "*Residual Sum of Squares*\n",
    "\n",
    "$$\n",
    "RSS(\\theta, D) = \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - h(\\vec{x}_i, \\vec{\\theta}))^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss(theta, D):\n",
    "    error = 0\n",
    "    for xi, yi in D:\n",
    "        prediction = h(xi, theta)\n",
    "        errori = (yi - prediction)**2\n",
    "        error += errori\n",
    "        print('truth=%g  prediction=%g error=%g' % (yi, prediction, errori))\n",
    "    return error / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "\n",
      "RSS=4\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    (npa([0,0]), -1),\n",
    "    (npa([1,0]), 1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,0]), -1),\n",
    "    (npa([1,1]), 1),\n",
    "    (npa([0,0]), 1),\n",
    "    (npa([0,1]), -1),\n",
    "]\n",
    "theta = npa([0,0])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "RSS=14.5\n"
     ]
    }
   ],
   "source": [
    "theta = npa([1,1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=0.5 error=2.25\n",
      "truth=1  prediction=-0.5 error=2.25\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-1 error=0\n",
      "\n",
      "RSS=3.625\n"
     ]
    }
   ],
   "source": [
    "theta = npa([0.5,-1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Pick optimal $\\vec{\\theta}^*$ to satisfy:\n",
    "\n",
    "$$ \\vec{\\theta}^* = argmin_\\vec{\\theta} \\hspace{.4cm} RSS(\\vec{\\theta}, D)$$\n",
    "\n",
    "**Solution:** Gradient descent\n",
    "\n",
    "while not converged:\n",
    "1. Compute gradient $\\nabla_\\vec{\\theta}$ of $\\vec{\\theta}$ w.r.t. RSS\n",
    "2. Change $\\vec{\\theta}$ in direction of $\\nabla_\\vec{\\theta}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_\\vec{\\theta} = \\{\\frac{\\partial RSS(h, D)}{\\partial \\theta_1} \\ldots \\frac{\\partial RSS(h, D)}{\\partial \\theta_v}\\}$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial RSS(h, D)}{\\partial \\theta_j} &=& \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)\\frac{\\partial}{\\partial \\theta_j} (y_i - \\theta \\cdot \\vec{x}_i)\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)(-x_{ij})\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To update parameters:**\n",
    "\n",
    "$$\\vec{\\theta}_j^{t+1} = \\vec{\\theta}_j^{t} + \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "$\\eta$ = \"learning rate\", to prevent \"jumping over\" minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        error = yi - h(xi, theta)\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * -xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(npa([0,0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-1 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-1 error=0\n",
      "truth=1  prediction=-3 error=16\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-2 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.5"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([-1, -2]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient_descent(h_fn, gradient_fn, error_fn, theta,\n",
    "                     learning_rate, D, tolerance, max_iters):\n",
    "    errori = error_fn(theta, D)\n",
    "    iters = 0\n",
    "    all_errors = [errori]\n",
    "    while True:\n",
    "        iters += 1\n",
    "        print('\\n\\niteration %d' % iters)\n",
    "        grad = gradient_fn(theta, D)\n",
    "        theta -= learning_rate * grad  # UPDATE!\n",
    "        newerror = error_fn(theta, D)\n",
    "        all_errors.append(newerror)\n",
    "        print('old error=%g   new error=%g  theta=%s\\n\\n' %\n",
    "              (errori, newerror, str(theta)))\n",
    "        error_diff = errori - newerror\n",
    "        if error_diff < 0 or errori - newerror < tolerance \\\n",
    "            or iters >= max_iters:\n",
    "            break\n",
    "        else:\n",
    "            errori = newerror\n",
    "            \n",
    "    plt.plot(all_errors, 'bo-')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('error')\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.8 error=3.24\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "truth=1  prediction=-1.6 error=6.76\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "old error=14.5   new error=6.4  theta=[-0.8 -0.8]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.28 error=0.5184\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.28 error=1.6384\n",
      "truth=1  prediction=0.2 error=0.64\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.08 error=0.8464\n",
      "old error=6.4   new error=4.2616  theta=[ 0.28 -0.08]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.152 error=1.3271\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.152 error=0.719104\n",
      "truth=1  prediction=-0.736 error=3.0137\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.584 error=0.173056\n",
      "old error=4.2616   new error=3.68618  theta=[-0.152 -0.584]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.1504 error=0.72182\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=0.1504 error=1.32342\n",
      "truth=1  prediction=-0.2752 error=1.62614\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.4256 error=0.329935\n",
      "old error=3.68618   new error=3.52599  theta=[ 0.1504 -0.4256]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.05536 error=0.892345\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=0.05536 error=1.11378\n",
      "truth=1  prediction=-0.52 error=2.3104\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.57536 error=0.180319\n",
      "old error=3.52599   new error=3.47882  theta=[ 0.05536 -0.57536]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.145216 error=0.730656\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=0.145216 error=1.31152\n",
      "truth=1  prediction=-0.403072 error=1.96861\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.548288 error=0.204044\n",
      "old error=3.47882   new error=3.46374  theta=[ 0.145216 -0.548288]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.128973 error=0.758688\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=0.128973 error=1.27458\n",
      "truth=1  prediction=-0.467814 error=2.15448\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.596787 error=0.162581\n",
      "old error=3.46374   new error=3.45839  theta=[ 0.1289728 -0.5967872]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1289728, -0.5967872])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHHlJREFUeJzt3XuUVOWZ7/HvU8KIiFzUCWZxN7HRmJFu2ozMkYEaPYE5\nJxHMcdQJBrwsjZyjE9HEjCazRiYrY7JyZhKTnFxnhAgjCah4HJyZoAbLKzLaFGiQS9ZRrlFyAYOI\nEKCe88feDU3bl+qmqt69a/8+a+3V1bt21f4BTT39vu/e72vujoiIZE8udAAREQlDBUBEJKNUAERE\nMkoFQEQko1QAREQySgVARCSjqloAzOxeM9tpZi+32/9XZrbezF4xs69WM4OIiHSsT5Xffz7wbWBB\n6w4zywOXAH/k7ofM7PQqZxARkQ5UtQXg7s8Cu9vt/p/AV939UHzMb6qZQUREOhZiDKABmGRmL5jZ\nk2Z2foAMIiKZV+0uoM7OOcTdJ5jZR4AlwJkBcoiIZFqIArANWArg7i+aWcnMTnP337Y/0Mw0UZGI\nSC+4u3V3TC26gCzeWv1f4CIAM2sA+nb04d/K3VO73XXXXcEzZDV/mrMrf/gt7fnLVdUWgJktAvLA\naWa2FbgLmAfMN7NXgAPArGpmEBGRjlW1ALj7jE6emlnN84qISPd0J3AV5fP50BGOS5rzpzk7KH9o\nac9fLutJf1GtmZknOZ+ISBKZGZ6QQWAREUkgFQARkYxSARARySgVABGRjFIBEBHJKBUAEZGMUgEQ\nEckoFQARkYxSARARySgVABGRjFIBEBHJKBUAEZGMUgEQEckoFQARkYxKfAEolUqhI4iI1KXEF4Dm\n5jkUi+tCxxARqTuJXxAGDtPYOIeWlnvI5RJfr0REgqujBWFybNo0mWKxGDqIiEhdSUEBEBGRakhB\nASjR0PAUTU1NoYOIiNSVxBeA0067hXnzblT/v4hIhVX1U9XM7jWznWb2cgfPfdbMSmZ2alfvUSp9\nk3POObd6IUVEMqrav1bPB6a232lmw4GPAlu6e4PGxhzLllUhmYhIxlW1ALj7s8DuDp76BnB7Oe9x\n9dWwYEFFY4mICAHGAMxsGrDN3V8p5/jLLoNnnoGdO6scTEQkY/rU8mRmdhLwBaLunyO7u3rNP/zD\nXEaNglmz4M478+Tz+WpGFBFJnUKhQKFQ6PHrqn4nsJmNApa5+3lm9mHgCWAf0Qf/cGAH8Mfu/qsO\nXuvuzooVcNttsGZNVaOKiNSFJN0JbPGGu//c3c9w9zPdfQywHWjq6MO/rXwedu2CtWurH1ZEJCuq\nfRnoIuB5oMHMtprZte0OcbrpAgLI5WDmTLjvvmqkFBHJpsRPBteab+NGmDwZtm+HPjUduRARSZck\ndQFVxNixMGYMLF8eOomISH1ITQGA6J4AdQOJiFRGarqAAHbvhtGjYfNmGDIkWCwRkUSruy4giD70\np0yBxYtDJxERSb9UFQDQ1BAiIpWSqi4ggIMHYcQIePppaGgIFExEJMHqsgsIoG9fmDFDrQARkeOV\nuhYARHcET5sGr78e3SQmIiJH1W0LAGDcOBg8GHox95GIiMRSWQBAg8EiIscrlV1AEK0PcPbZsG0b\nDBhQ42AiIglW111AAEOHwoUXwtKloZOIiKRTagsAaGoIEZHjkdouIID9+2HYMCgWYeTIGgYTEUmw\nuu8CAujXDy6/HBYuDJ1ERCR9Ul0A4OjVQAluyIiIJFLqC8CECdGH/6pVoZOIiKRL6guAmQaDRUR6\nI9WDwK22boWmJtixIxoXEBHJskwMArcaOTKaHmLZstBJRETSoy4KAGhqCBGRnqqLLiCAvXth+HDY\nuDG6S1hEJKsy1QUE0XxA06fDokWhk4iIpENVC4CZ3WtmO83s5Tb7vmZm681sjZk9ZGYDK3U+XQ0k\nIlK+arcA5gNT2+17DDjX3RuBXwB3Vupk+Tzs2hUtGCMiIl2ragFw92eB3e32PeHupfjbF4DhlTpf\nLgczZ6oVICJSjtBjANcB/1HJN5w1KxoHOHSoku8qIlJ/+oQ6sZl9ETjo7l0O286dO/fI43w+Tz6f\n7/J9x46FMWNg+XL42McqEFREJOEKhQKFXqyRW/XLQM1sFLDM3c9rs+8a4AbgInc/0MVry74MtK3v\nfx9WrIAlS3oRWEQk5ZJ0GajFW/SN2Z8DtwPTuvrwPx5XXhm1AHbv7v5YEZGsqvZloIuA54EGM9tq\nZtcC3wYGAI+b2Woz+26lzztkCEyZAosXV/qdRUTqR93cCdzeo4/C3XfD889XOJSISMKV2wVUtwXg\n4EEYMQKefhoaGiocTEQkwZI0BhBE374wY4YmiBMR6UzdtgAguiN42jR4/fXoJjERkSzIfAsAojUC\nBg+GXlweKyJS9+q6AIAmiBMR6UxddwEB7NwZ3R28fXs0ZbSISL1TF1Bs6FCYOBGWLg2dREQkWeq+\nAIC6gUREOlL3XUAA+/fDsGFQLEYLyIuI1DN1AbXRrx9cfjksXBg6iYhIcmSiAEDUDbRgASS4wSMi\nUlOZKQATJkQf/qtWhU4iIpIMmSkAZhoMFhFpKxODwK22boWmJtixIxoXEBGpRxoE7sDIkdH0EMuW\nhU4iIhJepgoAqBtIRKRVprqAAPbuheHDYePG6C5hEZF6oy6gTgwYANOnw6JFoZOIiISVuQIA6gYS\nEYGMFoB8HnbtihaMERHJqkwWgFwOZs5UK0BEsi1zg8CtNm6EyZOjdQL69KnKKUREgtAgcDfGjoUx\nY2D58tBJRETCqGoBMLN7zWynmb3cZt8QM3vMzDaa2XIzG1TNDF3RYLCIZFm1WwDzgant9t0BPOHu\nY4EVwJ1VztCpK6+MWgC7d4dKICISTlULgLs/C7T/eJ0OtP7efR9waTUzdGXIEJgyBRYvDpVARCSc\nEGMA73P3nQDu/ibwvgAZjmhdJ0BEJGuScP1Ll5f5zJ0798jjfD5PPp+v6MmnToXrr4dNm6ChoaJv\nLSJSE4VCgUKh0OPXVf0yUDMbBSxz9/Pi79cDeXffaWZnAE+6+zmdvLZql4G2ddtt0L8/fPnLVT+V\niEjVJekyUIu3Vv8KXBM/vhp4pAYZunT11dF6waVS6CQiIrVT7ctAFwHPAw1mttXMrgW+CnzUzDYC\nF8ffBzVuHAweDL1oQYmIpFZm7wRu7+tfj+YG0n0BIpJ25XYBqQDEdu6M7g7evj2aMlpEJK0qNgZg\nZieY2a2ViZVcQ4fCxImwdGnoJCIitdFtAXD3w8Ana5AlOE0NISJZUlYXkJl9A+gLLAbead3v7qur\nF622XUAA+/fDsGFQLEYLyIuIpFFFxwDM7MkOdru7X9SbcOWqdQEAmD0bRoyAL36xpqcVEakYDQL3\n0sqVcM01sGEDWLd/fSIiyVPRG8HMbJCZfd3MXoq3fww5jXM1TZgA7rBqVegkIiLVVe6NYPOAt4Er\n4m0P0VTPdcdMg8Eikg3ljgGscffG7vZVWoguIICtW6GpCXbsgH79an56EZHjUum5gN41s4lt3vxC\n4N3ehku6kSOj6SGWLQudRESkesptAYwDFgCt/f67gavd/eXOX3X8QrUAIOoCeuABePTRIKcXEem1\nil0FZGY54C/cfYmZDQRw9z2VidlNuIAFYO9eGD4cNm6M7hIWEUmLinUBuXsJ+Hz8eE+tPvxDGzAA\npk+HRYtCJxERqY5yxwCeMLPPmdkIMzu1datqsgTQ1UAiUs/KHQN4vYPd7u5nVj7SMecN1gUE0QIx\no0dHg8HjxgWLISLSI5UeA/gTd3+uUuHKFboAQDQlxLvvRusFiIikQaXnAiq6e1NFkvVAEgrAxo0w\neXK0TkCfPkGjiIiUpdL3AfzMzC4zy97sOGPHwpgxsHx56CQiIpVVbgvgbaA/cBjYT7TIu7v7wKqG\nS0ALAOD734cVK2DJktBJRES6V+kuoBxwFTDG3b9kZiOB97t7VadMS0oB2LUragVs3gxDhoROIyLS\ntUp3AX0HmMDRlcHeBv5PL7OlzqmnwpQpsHhx6CQiIpVTbgG4wN1vIur+wd13A39QtVQJpHsCRKTe\nlFsADprZCYADmNkfAqWqpUqgqVPh9ddh06bQSUREKqPcAvAt4GHgfWb298CzwN3Hc2Izu9PM1pnZ\ny2Z2v5klukXRty/MmAELFoROIiJSGWUvCWlmZwMXE10B9DN3X9/rk5qNAp4Eznb335vZYuDf3H1B\nu+MSMQjcau1amDYtagnkyi2dIiI1Vu4gcNm3Nrn7BmDDcaU6ag/we+BkMysRXWL6ywq9d9WMGweD\nB0OhABddFDqNiMjxCfJ7bDyI/I/AVmAH8Ja7PxEiS09pMFhE6kWQyQ3M7EzgVmAU8DvgQTOb4e7v\nmXx57ty5Rx7n83ny+XyNUnbsqqvgS1+K1gsYMCBoFBERAAqFAoVCocevK3sMoJLM7Argo+5+Q/z9\nTKJLTW9ud1yixgBaffzjcMUVMGtW6CQiIu9V6RvBKm0jMMHM+sXzC10M9HpQudbUDSQi9SBICwDA\nzG4HriGaX6gIXO/uB9sdk8gWwP79MGwYFIvRAvIiIklS0bmAQklqAQCYPRtGjIjWCxARSZKkdwGl\nXms3UELrk4hIt1QAemnChOjrqqrOhyoiUj0qAL1kpsFgEUk3jQEch61boakJduyAfv1CpxERiWgM\noAZGjoymh1i2LHQSEZGeUwE4TuoGEpG0UhfQcdq7F4YPh40bYejQ0GlERNQFVDMDBsD06bDoPbMY\niYgkmwpABagbSETSSAWgAvJ52LUrWjBGRCQtVAAqIJeDmTPVChCRdNEgcIVs3AiTJ8P27dAnyCoL\nIiIRDQLX2NixMGYMLF8eOomISHlUACpIg8EikibqAqqgXbuiVsDmzTBkSOg0IpJV6gIK4NRTYcoU\nWLw4dBIRke6pAFSYuoFEJC3UBVRhBw/C8OElvve9IqNGQVNTE7mc6qyI1I66gAL5+c/X4T6HK6/c\nwqRJW2hunkOxuC50LBGR91ALoIJKpRLNzXNYs+YejtbWEo2Nc2hpuUctARGpCbUAAigWi2zalOfY\nv9YcmzZNplgsBkolItIxFYAaSFEjRkQyRAWggpqammhoKAClNntLHDz4FJs3N4UJJSLSiWAFwMwG\nmdkDZrbezNaZ2QWhslRKLpdj3rwbaWycQ//+D9G//0OMG3cL//RPN3L77Tk+/Wl4553QKUVEIsEG\ngc3sR8BT7j7fzPoA/d19T7tjUjUI3KpUKh3p82+9DHTPHrj5Zli1Klo8prk5cEgRqVvlDgIHKQBm\nNhAouvsHujkulQWgKz/+MdxyC3zuc9GmC4NEpNKSXgDGAT8EXgXGAS8Bt7j7u+2Oq7sCALBlC3zq\nU9C3LyxYEK0pLCJSKeUWgFAz1/cBxgM3uftLZnYPcAdwV/sD586de+RxPp8nn8/XKGL1jBoFhQJ8\n5StRV9B3vwuXXRY6lYikVaFQoFAo9Ph1oVoAQ4GV7n5m/P1E4K/d/ZJ2x9VlC6CtVavgqquiZSXv\nuSdaZF5E5Hgk+kYwd98JbDOzhnjXxUTdQZlzwQVQLMLhwzB+PLz4YuhEIpIVIa8CGgf8M9AXeA24\n1t1/1+6Yum8BtLVkSXSl0K23wuc/DyecEDqRiKRRogeBy5W1AgCwdWu0wLwZLFwII0aETiQiaZPo\nLiDp3MiRsGIFTJ0aDRAvWRI6kYjUK7UAEuzFF2HGDJg4Eb71LTjllNCJRCQN1AKoAx/5SDRAnMtB\nU1N0xZCISKWoBZASDz4IN90En/kM3HGHBohFpHMaBK5D27bBrFnRJaMLF0Y3lImItKcuoDo0YgQ8\n8QR8/ONR99BPfhI6kYikmVoAKdXSEg0QT5gA3/42DBwYOpGIJIVaAHWuuRlWr4YTT4TGRli5MnQi\nEUkbtQDqwMMPw+zZ0SDxF74AfUJN8SciiaBB4IzZsQOuvhr274d/+RcYPTp0IhEJRV1AGTNsGDz2\nGFx6aTRAfP/9oROJSNKpBVCHVq+OBojPPx++8x0YNCh0IhGpJbUAMmz8+KgInHJKNED83HOhE4lI\nEqkFUOceeQRuvDEaJP6bv9EAsUgWaBBYjnjjjWiAeO/eaID4zDNDJxKRalIXkBzx/vfDT38Kl18e\nrUC2cCGoroqIWgAZs2ZNNEA8bhx873sweHDoRCJSaWoBSIcaG+Gll+DUU6PHzzwTOpGIhKIWQIY9\n+ijccANcfz387d9C376hE4lIJWgQWMry5ptwzTXw1lvRzWMf+ACUSiWKxSIATU1N5HJqKIqkibqA\npCxnnAH//u9HZxb9u79bx/jxc5g0aQuTJm2huXkOxeK60DFFpArUApAj1q4tccEFczhw4B6O/m5Q\norFxDi0t96glIJISagFIjx06VOSEE/Ic+2ORY8OGyaxcWQyUSkSqJeh9oWaWA14Ctrv7tJBZpHMH\nDsDFF8MHPxgtTt+6NTbCkCGh04lIb4WeGOAW4FVA61klQFNTEw0N97FmzaW07QIaN+4pVq78BOvX\nQ7EYbUuXwtq1cPrpxxaF8eOjG8+s28aniIQWbAzAzIYD84G/B27rqAWgMYDaKxbXcd11P2DTpskA\nnHVWgfnzZ9PUdO57ji2V4Be/OFoUWrdc7tii0NQUXV2kIQSR2kj8ZaBm9gDRh/8g4LMqAMlxPJeB\nukeL07QWg9Wro6+7d0d3H7e2Epqa4EMf0r0HItVQbgEI0gVkZh8Ddrr7GjPLA50GnTt37pHH+Xye\nfD5f7XiZl8vlaG5u7tVrzWD48Gi75JKj+3/722gaimIRHn8cvvY12LwZzjnn2JbCuHFw8smV+XOI\nZEWhUKBQKPT4dUFaAGZ2N/Ap4BBwEnAKsNTdZ7U7Ti2AOvbOO/DKK8e2FF59FUaOPNpKaN1OO628\n99RNbCIp6AI6EsBsMuoCktjBgxwz2FwsRi2HQYPeO64wYsSxg81Hxy/yADQ0FJg378YOxy9E6pkK\ngNSNUglee+29g82HDrXtOirx5S/PYcOGdN/EphaMVEJqCkBXVACkK2+8cbQYrFjRwpNPbsH9fxxz\nTN++DzFnzmg+/OFmBg6MlskcOJBjHp98cjIuW62HFkzaC1ja87dSAZBMaWlpYdKkLezbd2wB6NPn\nIS69dDT9+jXz9tuwZ0+0tX28fz8MGPDewtCbxyee2LtiUiqVaG6ew5o16W3BpL2ApT0/HC1g559/\nvgqAZMfxfIAeOhQtl9m+MPTm8eHDvSsev/xlCzffvIX9+48tYP37P8TTT4/u9VVZtZL2Apb2/HBs\nAdu377LkXgYqUmm5XI55827kuuvmHHMT27x5s7v9z9unT7QyWiVWRztwICoE3RWMbduO3f/GG9Fr\n29u3L1rGs2/fKGfbraN9obatW4u8+mqe9vNIrV8/mR/8oMjYsc2YRa2jXI5uH/f2ud4et3ZtMf7N\n/9j8mzZN5oUXiowf33ykZdfZ166eq3YXY6lU4rrrftCugHVPBUDqRlPTubS03NOmD/ebNf/N7cQT\no+3003v2ulKpiebmjqfheOGFT1AqRS2VENv+/d0f8+tfR62f9g4ehHnzoi4296NbqdT9494+15vj\nDh2Kim17+/ZBPn/0A7y1Q6L91+6ea68nRaOcY92L7N+fp6fze6oASF05npvYQuqsBTN//mz69Ut+\n90NnBey8855i1apPJH4akM7yNzY+RUtLZfL3pGj09NhiEaZO7biIdUVjACIJkuarUHoyj1QSpTn/\ne8cwdBWQiNRYmgsYpDt/2wK2b99fqACIiGSJLgMVEck4LQkpIiJdUgEQEckoFQARkYxSARARySgV\nABGRjFIBEBHJKBUAEZGMUgEQEckoFQARkYxSARARySgVABGRjFIBEBHJKBUAEZGMClIAzGy4ma0w\ns3Vm9oqZfSZEDhGRLAvVAjgE3Obu5wJ/AtxkZmcHylI1hUIhdITjkub8ac4Oyh9a2vOXK0gBcPc3\n3X1N/HgvsB4YFiJLNaX9hyjN+dOcHZQ/tLTnL1fwMQAzGw00AqvCJhERyZagBcDMBgAPArfELQER\nEamRYEtCmlkf4FHgP9z9m50co/UgRUR6IdFrApvZAuA37n5bkAAiIhkXpACY2YXA08ArgMfbF9z9\npzUPIyKSUcFaACIiElbwq4A6YmZ/bmYbzGyTmf116Dw9ZWb3mtlOM3s5dJaeSvtNemZ2opmtMrNi\n/Ge4O3Sm3jCznJmtNrN/DZ2lp8xss5mtjf8N/jN0np4ws0Fm9oCZrY9/fi4InalcZtYQ/52vjr/+\nrrv/v4lrAZhZDtgEXAz8EngR+Et33xA0WA+Y2URgL7DA3c8LnacnzOwM4Ax3XxNfpdUCTE/Z339/\nd99nZicAzwGfdffnQufqCTO7FWgGBrr7tNB5esLMXgOa3X136Cw9ZWY/Ap5y9/nxhSr93X1P4Fg9\nFn+ObgcucPdtnR2XxBbAHwO/cPct7n4Q+AkwPXCmHnH3Z4HU/fBDfdyk5+774ocnEv2Mp+rfwsyG\nA/8d+OfQWXrJSOZnS5fMbCDwp+4+H8DdD6Xxwz/2X4H/19WHPyTzH2kY0Db0dlL2AVQv0nqTXtx9\nUgTeBAru/mroTD30DeB2oosj0siBx83sRTO7IXSYHhgD/MbM5sfdKD80s5NCh+qlK4Efd3dQEguA\nJECab9Jz95K7NwHDgUlmNjl0pnKZ2ceAnXErzOItbS509/FErZib4i7RNOgDjAe+E+ffB9wRNlLP\nmVlfYBrwQHfHJrEA7ABGtvl+eLxPaiTu+3wQWOjuj4TO01tx8/3fgPNDZ+mBC4FpcT/6j4E/i++Z\nSQ13fyP++mvgYaJu3TTYDmxz95fi7x8kKghp89+Alvjvv0tJLAAvAh80s1Fm9gfAXwKpuxKC9P72\nBjAPeLWzO7STzMxON7NB8eOTgI8Ca8KmKp+7f8HdR7r7mUQ/+yvcfVboXOUys/5x6xEzOxmYAvw8\nbKryuPtOYJuZNcS7LgbS1n0I8EnK6P6BqMmTKO5+2MxuBh4jKlD3uvv6wLF6xMwWAXngNDPbCtzV\nOrCUdPFNelcBr8T96Gm7Se/9wH1m1joQudDdfxY4U5YMBR6Op3HpA9zv7o8FztQTnwHuj7tRXgOu\nDZynR8ysP9EA8KfLOj5pl4GKiEhtJLELSEREakAFQEQko1QAREQySgVARCSjVABERDJKBUBEJKNU\nACQTzOzZ+OsoM/tkhd/7zo7OJZJ0ug9AMsXM8kTTQ1/Sg9ec4O6Hu3j+bXc/pRL5RGpJLQDJBDN7\nO374FWBiPNvjLfHMoV+LF5FZ0zp7pZlNNrOnzewRYF287+F4hstXzOz6eN9XgJPi91vY7lyY2f+O\nj19rZle0ee8n2yw8srB2fxMiRyVuKgiRKmlt6t5B1AKYBhB/4L/l7hfEc089Z2atUxc0Aee6+9b4\n+2vd/S0z6we8aGYPufudZnZTPHvkMecys8uA89z9j8zsffFrnoqPaQQ+RDRl9XNm9l/c/fkq/dlF\nOqQWgGTdFGBWPO/RKuBU4Kz4uf9s8+EPMMfM1gAvEM1SexZdu5B4Ui53/xVQAD7S5r3f8KgPdg0w\n+vj/KCI9oxaAZJ0Bf+Xujx+zM1pD4J12319EtMTeATN7EujX5j3KPVerA20eH0b/FyUAtQAkK1o/\nfN8G2g7YLgf+V7wGAmZ2VjyjYnuDgN3xh//ZwIQ2z/2+9fXtzvUMcGU8zvCHwJ8CqVokXeqbfuuQ\nrGgdA3gZKMVdPj9y92/GS1+ujqeQ/hVwaQev/ykw28zWARuBlW2e+yHwspm1uPvM1nO5+8NmNgFY\nC5SA2939V2Z2TifZRGpKl4GKiGSUuoBERDJKBUBEJKNUAEREMkoFQEQko1QAREQySgVARCSjVABE\nRDJKBUBEJKP+P00n732gUQvqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107bed518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(h, gradient, rss, theta, .2, D, .01, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does our error function make sense?**\n",
    "\n",
    "\n",
    "iteration 1  \n",
    "truth=-1  prediction=0 error=1  \n",
    "truth=1  prediction=-0.8 error=3.24  \n",
    "**truth=-1  prediction=-1.6 error=0.36**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above assumes that the output variable $y_i$ is a real number. Thus, this is a model of <span>**regression**</span>.  \n",
    "\n",
    "When $y$ is disrete, the problem is one of <span>**classification**</span>.  \n",
    "\n",
    "One could use the linear model above to do classification. Assume the binary case where $y_i$ can either be $-1$ or $1$. We can convert the regression model to a classifier by assuming that if the model outputs a number greater than 0, then predict 1; otherwise, predict -1.\n",
    "\n",
    "However, this can cause weird things to happen in our update rule: \n",
    "\n",
    "$$\\vec{\\theta}_j^{t+1} = \\vec{\\theta}_j^{t} + \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "\n",
    "Suppose the true value of $y_1$ is $1$, and the model (dot product) returns 2. The instance is technically classified correctly, but the update still counts this as an error of size 1 (since $y_i -\\theta \\cdot x_i$ is 1). In fact, the update considers this error equivalent to a dot product of $0$, which would in fact result in a classification error.\n",
    "\n",
    "This is clearly not what we want – in fact, our gradient descent algorithm may never converge, since we can always make our correct classifications “more correct” by cranking up the value of $\\theta$.\n",
    "\n",
    "The way around this is to change our model. Rather than regression, we need classification. We can do this by passing the dot product $x_i \\cdot \\theta$ through a “squashing function” (the **logistic function**) that ensures its value is always between 0 and 1: \n",
    "\n",
    "$$h(\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "This is called **logistic regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUTCIiEgjCgYREWlEwSAiIo38P1xapw41jxNhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c5a748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import exp\n",
    "def logistic(x, theta):\n",
    "    return 1 / (1 + exp(-h(x, theta)))\n",
    "    \n",
    "x = npa([1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(-10, 10), [logistic(x, theta) for theta in range(-10, 10)])\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('logistic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $h(x_i)$ will always be between 0 and 1, and will sum to one for both classes, we have the right to call this a <span>**probability**</span> $p(y_i=1|\\vec{x}_i)$.  \n",
    "\n",
    "$$h(\\vec{x}_i) = p(y_i=1|\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "and, for binary classification, the probability of a negative example:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = 1 - p(y_i=1|\\vec{x}_i)\n",
    "$$\n",
    "\n",
    "with some algebra, it turns out that:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = \\frac{1}{1 + e^{\\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$\n",
    "\n",
    "Because of this, if $y_i \\in \\{-1, 1\\}$, we can write:\n",
    "\n",
    "$$\n",
    "p(y_i|\\vec{x}_i) =  \\frac{1}{1 + e^{-y_i \\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a good error function for logistic regression?**\n",
    "\n",
    "We can now rephrase our learning objective as maximizing the <span>*joint probability of the true labels for all training instances.*</span>  \n",
    "\n",
    "Since we assume each instance is drawn independently, we can write this joint probability as a product of individual probabilities: \n",
    "\n",
    "$$p(y_1 \\ldots y_n|\\vec{x}_1 \\ldots \\vec{x}_n) = p(y_1|\\vec{x}_n) * p(y_2|\\vec{x}_2) * \\ldots * p(y_n|\\vec{x}_n) = \\prod_{i=1}^{n}p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "Because we’re used to minimizing functions using gradient descent, rather than maximizing the probability, we can instead minimize the negative probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i)\n",
    "$$\n",
    "\n",
    "Note that this is very similar to RSS, but by using probabilities, we ensure that the output for each instance is always between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following our learning recipe, our next step is to minimize $E(D,h)$ using gradient descent.  \n",
    "\n",
    "Computing the gradient of $E(D,h)$ in its current form is rather hard. So, we can simply transform it to something that’s easier to take the gradient of: \n",
    "\n",
    "$$E(D,h) = - \\ln \\prod_{i=1}^n  p(y_i|\\vec{x}_i) = -\\sum_i \\ln p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "This is called the <span>**negative log likelihood**</span>. It turns out that minimizing \\(f(x)\\) or \\(\\ln f(x)\\) results in the same answer, so we can make this transformation without affecting our final solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def nll(theta, D):\n",
    "    total = 0\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        print('truth=%g  pr(true label)=%g' % (yi, pred))\n",
    "        total += log(pred)\n",
    "    return -total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we’re ready to calculate the gradient with respect to one parameter $\\theta_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E(D,h)}{\\partial \\theta_j} & = & \\frac{\\partial}{\\partial \\theta_j}- \\ln \\prod_i \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\\\\n",
    "& = &  \\frac{\\partial}{\\partial \\theta_j}-  \\sum_i \\ln \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{(by definition of log of products)}\\\\\n",
    "& = &  -  \\sum_i 1 + e^{-y_i x_i \\cdot \\theta} \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad  \\hbox{  (by }\\frac{d}{dx}\\ln(f(x)) = \\frac{1}{f(x)} \\frac{d}{dx}f(x) ) \\\\\n",
    "& = &  -  \\sum_i (1 + e^{-y_i x_i \\cdot \\theta})\\Big(\\frac{-y_ix_{ij} e^{-y_ix_i \\cdot \\theta}}{(1 + e^{-y_ix_i\\cdot \\theta})^2}\\Big) \\quad \\hbox{    (by quotient and chain rules) }\\\\\n",
    "& = & - \\sum_i \\frac{-y_i x_{ij} e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{     (by algebra) }\\\\\n",
    "& = & \\sum_i y_i x_{ij} (1 - p(y_i | x_i)) \\quad \\Big( \\hbox{by }\\frac{e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} = 1 - p(y_i|x_i) \\Big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the final logistic regression update is: \n",
    "\n",
    "$$\n",
    "\\vec{\\theta}_j^{t+1} \\leftarrow \\vec{\\theta}_j^{t} + \\eta \\sum_i y_i x_{ij}(1-p(y_i|\\vec{x}_i))\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_logistic(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        error = yi * pred\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.708797\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.291203\n",
      "truth=1  pr(true label)=0.864386\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.276347\n",
      "old error=8.70686   new error=8.39193  theta=[ 0.88954916  0.96265502]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.687504\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.312496\n",
      "truth=1  pr(true label)=0.848058\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.282727\n",
      "old error=8.39193   new error=8.12073  theta=[ 0.78847403  0.930974  ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.667424\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.332576\n",
      "truth=1  pr(true label)=0.832212\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.288059\n",
      "old error=8.12073   new error=7.88988  theta=[ 0.69655599  0.9048294 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.648718\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.351282\n",
      "truth=1  pr(true label)=0.817183\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292355\n",
      "old error=7.88988   new error=7.69544  theta=[ 0.61340767  0.88397173]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.631466\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.368534\n",
      "truth=1  pr(true label)=0.803223\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.29566\n",
      "old error=7.69544   new error=7.53326  theta=[ 0.53850913  0.86805228]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.615679\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.384321\n",
      "truth=1  pr(true label)=0.790493\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.298039\n",
      "old error=7.53326   new error=7.39923  theta=[ 0.47124912  0.85665135]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.601319\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.398681\n",
      "truth=1  pr(true label)=0.779073\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299578\n",
      "old error=7.39923   new error=7.28939  theta=[ 0.4109653   0.84930736]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 8\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.588309\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.411691\n",
      "truth=1  pr(true label)=0.768973\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300369\n",
      "old error=7.28939   new error=7.20017  theta=[ 0.35697953  0.84554326]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 9\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.57655\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.42345\n",
      "truth=1  pr(true label)=0.760152\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300506\n",
      "old error=7.20017   new error=7.12833  theta=[ 0.30862573  0.84488814]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 10\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.565931\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.434069\n",
      "truth=1  pr(true label)=0.752532\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300085\n",
      "old error=7.12833   new error=7.07108  theta=[ 0.26527013  0.84689312]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 11\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.556341\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.443659\n",
      "truth=1  pr(true label)=0.746014\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299193\n",
      "old error=7.07108   new error=7.026  theta=[ 0.2263242   0.85114197]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 12\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.547668\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.452332\n",
      "truth=1  pr(true label)=0.740488\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.297913\n",
      "old error=7.026   new error=6.99103  theta=[ 0.19125179  0.85725705]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 13\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.539808\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.460192\n",
      "truth=1  pr(true label)=0.735843\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.296316\n",
      "old error=6.99103   new error=6.96444  theta=[ 0.15957171  0.86490179]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 14\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.532668\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.467332\n",
      "truth=1  pr(true label)=0.731969\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.294468\n",
      "old error=6.96444   new error=6.94478  theta=[ 0.13085709  0.87378049]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 15\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.526159\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.473841\n",
      "truth=1  pr(true label)=0.728766\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292425\n",
      "old error=6.94478   new error=6.93083  theta=[ 0.10473274  0.8836365 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 16\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.520207\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.479793\n",
      "truth=1  pr(true label)=0.726139\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.290234\n",
      "old error=6.93083   new error=6.92157  theta=[ 0.08087117  0.89424926]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08087117,  0.89424926])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VPW9//HXZwCXiFCtFn+CiFFxoWKGWMEFiNS9FbV6\ni3uF1sa1pPZhW732YnvtrbXV69LWQhVE64IVarFa6xostaANE9SIRGUp4s+FIooEBTKf+8eZQCaZ\n7Jk5ZzLv5+Mxj2TOnJz5BAjvfM93M3dHRESkQSzsAkREJFoUDCIikkbBICIiaRQMIiKSRsEgIiJp\nFAwiIpIm68FgZpPN7JXU4zstnHObmb1hZtVmVpLtmkREpGVZDQYzGwZ8EzgMKAG+ambFTc45CdjX\n3fcHyoHfZrMmERFpXbZbDAcBC939M3evB54HvtbknFOBewDcfSHQ38wGZLkuERFpQbaD4VVgtJnt\nYmZFwMnAXk3OGQisavR8deqYiIiEoHc2L+7ur5vZz4GngE+ABFCfzfcUEZGuyWowALj7DGAGgJn9\nlPTWAQQthMatiEGpY2nMTIs6iYh0grtbR87Pxaik3VMfBwOnA/c3OWUucEHqnFHAOnd/L9O13D3y\njylTpoReg+pUnflao+rs/kdnZL3FAMw2s12BzcCl7v6xmZUD7u7T3P1xMzvZzN4ENgATc1CTiIi0\nIBe3ksZkODa1yfPLs12HiIi0j2Y+d7OysrKwS2gX1dm98qHOfKgRVGcUWGfvQeWamXm+1CoiEhVm\nhket81lERPKLgkFERNIoGEREJI2CQURE0igYREQkjYJBRETSKBhERCSNgkFERNIoGEREJI2CQURE\n0igYREQkjYJBRETSKBhERCSNgkFERNIoGEREJI2CQURE0uRVMCSTybBLEBHp8fIqGEpLK0gkasIu\nQ0SkR8urrT2hnpKSCqqqbiEWy6tMExEJRQFs7RmjtnYsiUQi7EJERHqsPAsGERHJtjwLhiSDB88j\nHo+HXYiISI+VV8EwaNBkNm8u57PP8qpsEZG8kledz1u21HPeeTH69YOpU8OuSEQk+np853OvXjGm\nToVnn4UHHwy7GhGRnimvWgwNtSYScMIJ8MILsN9+IRcmIhJhPb7F0CAehylT4Otfh88+C7saEZGe\nJS9bDADucOaZsOeecPvtIRYmIhJhBdNiADCDu+6Cxx6DOXPCrkZEpOfI2xZDgxdfhK9+FRYuhH32\nCaEwEZEIK6gWQ4PDD4err4YJE2DTprCrERHJf3nfYoCgv+HUU2H//eGmm3JcmIhIhBVkiwGC/oa7\n74aHH4ZHHw27GhGR/NYjWgwNXngBTj8dXnoJBg/OUWEiIhEWyRaDmV1tZjVm9rKZ3Wdm2zV5fayZ\nrTOzRanHtZ19ryOPhCuvhLPPhs2bu167iEghymowmNnewEVA3N2HA72BszKc+ry7j0g9ru/Ke151\nFfTrB//1X125iohI4cp2i+FjYBOwk5n1BoqAdzKc16FmTmtiMbjnHrj3Xnjiie66qohI4chqMLj7\nh8BNwL+A1cA6d386w6lHmFm1mT1mZgd39X133x3uuw8mToR3MsWQiIi0qHc2L25mxcB3gb2Bj4CH\nzewcd7+/0WlVwGB3rzOzk4BHgKGZrnfddddt/bysrIyysrIW33vsWLj0UjjnHHj6aeid1e9URCQa\nKisrqays7NI1sjoqycy+Dhzn7helnp8PjHT3y1v5muVAqbuvbXK8zVFJTdXXw/HHw9FHw49/3PH6\nRUTyXRRHJS0FRpnZDmZmwJeBJY1PMLMBjT4/nCCs1tINevUKbin97nfwzDPdcUURkZ4v230Mi4F7\nCG4XLU4dnmZm5Wb27dTzM83sVTNLALcAE7qzhj32CDqjL7gA3nuvO68sItIz9agJbq350Y9gwYJg\npFKvXt1YmIhIhEXxVlJkTJkSbOpzww1hVyIiEm0F02IAWL0aSkvhwQeT7LxzAoB4PE4sVjD5KCIF\nRi2GNgwcCNdeW8Pxx1cwevRKxoxZSWlpBYlETdiliYhERkG1GJLJJKWlFVRX38K2TExSUlJBVdUt\najmISI+jFkMbEokEtbVlpH/bMWprx5JIJEKqSkQkWgoqGEREpG0FFQzxeJyhQyuBZKOjSQYOnEc8\nHg+nKBGRiCmoPgaARKKGSZOmUls7FoABAyr5+OOLefHFYRQXd/nyIiKR0pk+hoILBgg6oRv6FOLx\nOHfcEeP224Md4HbdtVveQkQkEhQMXXDllbBoEfz1r7D99ll7GxGRnFIwdEF9PfzHf0DfvjBzJli3\nbR0kIhIeDVftgl694Pe/h9df1xLdIlLYtH1NI0VF8OijMGoUFBcHK7KKiBQaBUMTAwbAY4/BMcfA\nXnsFH0VEColuJWVw8MHwwAMwYQIsWdL2+SIiPYmCoQXjxsEvfgFf+Yo2+BGRwqJgaMU3vgHnnw/j\nx0NdXdjViIjkhoartsE96ITesAH+8Aft/iYi+UXDVbPADO68E/79b/j+98OuRkQk+xQM7bD99vDH\nPwajlX7zm7CrERHJLg1Xbaddd4XHH4ejjoK99w46pUVEeiK1GDqguDhoOVx4IWhfHxHpqRQMHTRq\nFNxxB5xyCqxaFXY1IiLdT7eSOuHMM2HFiuB20vz50K9f2BWJiHQfDVftJHe49FJYvjxYX6lPn7Ar\nEhFpTstu59iWLcHkt732gt/8Jkl19bbNf2Ix3aUTkfApGEKwfj2UltbwySdT+eijMgCGDq1k+vRy\n4vFhodYmIqJgCEEymeSQQyp47bVb2NaXn6SkpIKqqlvUchCRUGnmcwgSiQQrVpSR/kcZo7Z27NZ9\npUVE8omCQURE0igYuigejzN0aCWQbHQ0yZ57ziMej4dTlIhIFygYuigWizF9ejklJRUUFc2mqGg2\nxcWTWbOmnL/9TX+8IpJ/1PncTZLJ5NY+hXg8TmVljAkTYNasYNMfEZEwaFRSxMybF8ySvv9+OO64\nsKsRkUKkUUkRM3YszJkD554LTzwRdjUiIu2T9WAws6vNrMbMXjaz+8xsuwzn3GZmb5hZtZmVZLum\nXBo9Gh55JNgF7vHHw65GRKRtWQ0GM9sbuAiIu/twgkX7zmpyzknAvu6+P1AO/DabNYXhyCOD9ZQu\nvDD4KCISZdluMXwMbAJ2MrPeQBHwTpNzTgXuAXD3hUB/MxuQ5bpybuTIYAe4b30r2NNBRCSqshoM\n7v4hcBPwL2A1sM7dn25y2kCg8c4Gq1PHepwvfQn+8he45BJ4+OGwqxERySzbt5KKge8CewN7An3N\n7JxsvmfUjRgRdERffnkwlFVEJGqyvVHPYcDf3X0tgJnNAY4E7m90zmpgr0bPB6WONXPddddt/bys\nrIyysrLurTZHSkrgqafg+OOhvh7OKeioFJHuVFlZSWVlZZeukdV5DGZ2KPB74EvAZ8AM4CV3/3Wj\nc04GLnP3r5jZKOAWdx+V4Vp5N4+hLTU1wfyGG24IRi2JiHS3zsxjyGqLwd0Xm9k9QBVQDywCpplZ\nefCyT3P3x83sZDN7E9gATMxmTVEybBg880wQDvX1MLFgvnMRiTLNfI6ApUvh2GNhypRg1JKISHeJ\nXItB2ueAA+C554I1lerrobw87IpEpJApGCJiv/22hcOWLXDZZWFXJCKFSsEQIfvuC5WV28LhiivS\nV2zVNqEikgvqY4iglSvhqKNqcJ/KunVlAAwdWsn06eXE48NCrU1E8ouW3e4hkskkhxxSwWuv3cK2\nOYhJSkoqqKq6RS0HEWk3LbvdQyQSCVasKCP9rydGbe3YrbeWRESyRcEgIiJpFAwRFI/HGTq0Ekg2\nOprEfR677RYPpygRKRhtBoOZ9TKz7+aiGAnEYjGmTy+npKSCoqLZFBXN5tBDJ1NeXs6RR8ZYsCDs\nCkWkJ2tX57OZvejuh+egntZqKJjO5wbJZPPhqn/+M0yaBDffDOedF3KBIhJ5WRuVZGb/C/QBZhGs\nZwSAuy/qaJGdVYjB0JJXX4Xx42HCBPjpT0GDlESkJdkMhucyHHZ3H9eRN+sKBUO6NWvgjDPgc5+D\n3/8edt457IpEJIo0j6HAbNoULJ2xcCHMnQtDhoRdkYhETdbmMZhZfzO72cz+mXrcZGb9O1emdJft\ntoNp0+Cb34QjjoD588OuSER6gvbenZ4OrAe+nnp8TLDpjoTMDCZPhrvvhq99DWbob0VEuqi9fQzV\n7l7S1rFs0q2ktr3+OpxyStAxfeON0KtX2BWJSNiyuSTGRjM7utEbHQVs7MgbSfYdeGDQ31BdHQTE\nRx+FXZGI5KP2BsPFwK/NbIWZrQB+BWg7mQjadVd44gnYZ5+g3+Gtt8KuSETyTXtmPseAA9z9UGA4\nMNzd4+7+ctark07p0wd+/Wu4/HI46qhgAyARkfZqbx/DP939sBzU01oN6mPohGefhbPPhp/8JNgy\nNNNsahHpubI5we0GYA3NZz6v7WiRnaVg6Lw33gg6pEtKaliyZCpvvFEGaPMfkUKQzWBYnuGwu3tx\nR96sKxQMXbN2bZIhQypYv16b/4gUkqyMSkr1MZzn7vs0eeQsFKTrli9PUF9fhjb/EZG2tBkM7p4k\nGIUkIiIFoL33D54xszPMrEPNEYmOljb/icW0+Y+IpGtvH8N6oAioBz4FjKCPoV92y0urQX0MXZRI\n1DBp0lRqa8cCsN9+lYwefTEPPTSMm2+Gc88NltgQkZ4jm53PMeBcYB93/4mZDQb+n7sv7FypHadg\n6B6ZhqsuWgTnnw/DhsEdd8DnPx9ykSLSbbIZDHcQ3IMY5+4HmdkuwJPu/qXOldpxCobs+vRTuOYa\nmDUL7rwTTjop7IpEpDtkMxgWufsIM0u4ezx1bHFqNnROKBhy47nn4MIL4eST4Ze/hJ12CrsiEemK\nbC6it9nMegGeeqPdSe/FlB7imGPg5Zehrg5KSmDBgrArEpFca28w3Ab8EfiCmf0UmA/8T9aqklD1\n7w8zZ8INN8Bpp8G11wa7xYlIYWj31p5mdiDwZYIRSc+4+5JsFpbh/XUrKQTvvhvsEPfuu3DvvXDw\nwWFXJCIdoT2fJSvc4Xe/g//8z+Dxne+AVtAQyQ8KBsmqt96CCy6AHXYIthAdPDjsikSkLdnsfBZh\n333h+efh2GPhsMOCW0vuwdyIqqoqqqqqSCY1JkEk36nFIJ1SXQ3nnQcDBtTw/vtTWbasDNBS3iJR\nE7lbSWY2lGAPByfotC4GfuTutzU6ZyzwJ2BZ6tAcd78+w7UUDBFTVxcs5f3BB1rKWySqOhMMvbNV\nDIC71wINE+JiwNsEw16bet7dx2ezFul+S5Yk2LChjJaW8i4tLQ2pMhHpilz+Sncs8Ja7r8rwmpZu\n60E2bYKNG8OuQkQ6K5fBMAF4oIXXjjCzajN7zMw0Uj5PtLSUd9++8zjrrDj33QfqixbJPznpfDaz\nPsA7wMHu/kGT1/oCSXevM7OTgFvdfWiGa6iPIYKaLuW9//6VzJhxMXV1w6iogF694NZbYeTIkAsV\nKVCR63ze+iZm44FL3f3Edpy7HCh197VNjvuUKVO2Pi8rK6OsrKy7S5VOyLSUd3A8GNJ6zTUwbhz8\n7GcwaFCYlYr0fJWVlVRWVm59/uMf/ziywfAA8IS7z8zw2gB3fy/1+eHAQ+4+JMN5ajHkqU8+CdZd\nuuOOYNb0VVdBUVHYVYkUhkhOcDOzIoKO5zmNjpWb2bdTT880s1fNLAHcQtAXIT1I375w/fWwaBG8\n9hoceCDcf38wOU5EokcT3CTn5s+Higro0yfofzj88LArEum5ItliEGnq6KPhxRehvBxOPz1Yf2n1\n6rCrEpEGCgYJRSwW7BS3dCnstRcMHw4/+UmwQRBo/SWRMOlWkkTCihXwgx8EO8aVl9fw0ENTeeON\nMkDrL4l0RWSHq3YHBUNhmDcvyUknVbBxo9ZfEukO6mOQvNe3bwKzMlpaf0lEsk/BIHnh00/hH//Q\nEFeRXFAwSKS0tP7SoEHz+O1v44wYAbNmwZYt4dQnUggUDBIpsViM6dPLKSmpoKhoNkVFszn00Mk8\n8kg5r7wS4/rr4fbbg0lyU6cGLQkR6V7qfJZIamn9pQbz58PPfw7//GcwWe7ii6F//zAqFYk2jUqS\ngvPKK3DjjfD443DRRUFI7LFH2FWJRIdGJUnBOeSQYAXXqirYsAEOPhguuQTeeqv5uZo0J9I+Cgbp\nEYYMCfoeXn8ddtst2P/hrLOgYYRrIlFDaWkFY8asZMyYlZSWVpBI1IRas0hU6VaS9Ejr18O0aXDz\nzfDFLyZZtqyCN9/UpDkpPLqVJJKy887wve/BsmVw+OEJ3nqrDE2aE2kfBYP0aNtvD6edBjvu2Pw1\ndTOIZKZgkB6vpUlzmzfPo6Iizt13B7vMiUhAwSA9XkuT5l54oZwrr4wxZ06w9PekScH8CHVlSaFT\n57MUjNYmzb37bjDsdcaMYLmNiRODDYQGDgyrWpHuoQluIl3kDgsXBgHxhz/AqFFBSIwfH/RXNNXW\nDG2RsCkYRLpRXR3MmQPTpwczrM8+O7jdVFISvJ5I1DBp0lRqa8sAbSgk0aRgEMmS5cth5sygJbHr\nrvCNbyS5664KXn1VcyMk2hQMIlmWTMJzz8Evf1nFE0+sBL6W9npR0Wyef34IpaWl4RQo0kRngqF3\ntooR6YliMfjyl+Fzn4N582DjxvTXt2wJZl2L5DO1d0U6IR6Pc8ABlTSdG7HDDvM45ZQ4xx4brN20\nYkU49Yl0hW4liXTSts7nsQDsv38lM2ZczNChw3jqKfjTn+DPf4Y994RTTw1GNpWWgnWoUS/SNepj\nEMmxtoar1tcHe1XPnRsExYYNcMopQVAcc4yGwEr2KRhEIm7p0m0h8corcNxxQUicfDJ8/vMaAivd\nT8Egkkc++CC41TR3Ljz7LJSUJHnzzQreeUdDYKX7KBhE8tTGjTB1ahVXXbWSLVvSh8DuuONs/vY3\nDYGVztF+DCJ5ascdYfRo2G675q9t3AhnnAHf/jbcdx+sWpX7+qSwKBhEIqKl5cEPPXQec+bE+eIX\ngyU6RoyA4mK48MJgJvayZa2vCKu9rqWjdCtJJEJaGgLbuPPZHZYsgeefDybZzZsXTLwbOxbGjAk+\nHnBAMCxWndmiPgaRHqCjw1Xd4a230oNi40YYPTrJggUVrF6tzuxCpmAQEQBWroSZM6v47/9u3pm9\n/fazmT17CCefXKrJdgVAwSAiW1VVVTFmzErq6tKDIRabTf/+Q+jVq5R4nK2PESNgv/2C21Jt0SS8\n/KFRSSKyVUud2cOHz+ODD+IsXgyTJ8POOwebEp1wQrA44NFHwxVXBB3b1dWwaVP6dROJGkpLKxgz\nZiVjxqyktLSCRKImd9+YZF1WWwxmNhSYBThgQDHwI3e/rcl5twEnARuAC929OsO11GIQ6aD2dGY3\n9uGHQRgsWgSJRPBYvhwOOihoVRx6aJLbbqvgzTfVb5EvIn0rycxiwNvASHdf1ej4ScDl7v4VMxsJ\n3OruozJ8vYJBpBO6etunrg5efjkIiSefrGLu3JUkk+m3p7bbbjZ33TWE8eNL6dcvnDols6gHw/EE\nrYXRTY7/FnjO3Welni8Bytz9vSbnKRhEQtZSv0WvXrPZd98hvP12EAxDh257HHBA8LG4OPMEPtCw\n2myK+kY9E4AHMhwfCDSey7k6dey9DOeKSIiCfouZVFefRuNbSYccMo+qqtMxg9WrobZ226OyMvi4\nahUMGtQ8MPbbL8nEiVNZvHjb7anq6tOYNKnrt6fUCumcnASDmfUBxgM/7Mp1rrvuuq2fl5WVUVZW\n1qW6RKRjYrEY06eXM2lSRVq/xfTpF2/9T3fQoOAxblz6127aFPRX1NYGq8wmEjBrFtTUJFizpoz0\nsTAxliwZy6xZCU44oZRddun4PhbNWyEzC6IVUllZSWVlZZeukZNbSWY2HrjU3U/M8FrTW0mvA2N1\nK0kkurrzN/HWhtUOGTKENWtK2bIF9tqr9cfOO6fXV1paQXV193eS51srJMq3ks4m820kgLnAZcAs\nMxsFrGsaCiISLbFYrNtWe23p9tTw4cHtqVgMPv44uBXV+PH3v6c/3267bSGx444JamrKaNoKqa0d\nSyKR6HTt2WqFRC1sst5iMLMiYCVQ7O7rU8fKAXf3aannvwJOJBiuOtHdF2W4jloMIj1UR4fVNuUO\na9c2Do0qbrqp+axvmM1uuw1h4MBSvvAF2H334NHwedOP/fptu4WVrVZItjreG8LmsMMOi+6opK5S\nMIj0bN35W3NL/4kPH17Bo4/ewpo1MT74AN5/n1Y/btq0LSi2376Kl15aSX198yVGpk4dwsiRpfTv\nD/37B8uot6dPJBdhU1d3RmRvJYmItKo7b0+11Ek+Y8bFDB4cY/Dg9l1n48ZtQfHCC8HEv/r69HM2\nb4Ybbww+fvRR8Egm2RoS/fsHM8ozPf/wwwSvvVZG01teS5eOZcGCBEcc0fH1rJLJJJMmTW0SNh2j\nFoOI9Fi5aIVk+u3+00+3hUTDY9265s+XLavi8cebTxiE2fTpM4QtW0opKiLjY6edMh//8MMq7rxz\nJZs3N1wzup3PIiI5l4tWSOOhug122CF4DBjQ+jWTyTilpc073ktKgo73ZDJotdTVZX5s2ND82Dvv\ntL5xU3uoxSAi0gHdPYKoqx3vmepLb9lEeEmMrlIwiEhPlc2wqas7U8EgIiIarioiIi3QRj0iItJl\nCgYREUmjYBARkTQKBhERSaNgEBGRNAoGERFJo2AQEZE0CgYREUmjYBARkTQKBhERSaNgEBGRNAoG\nERFJo2AQEZE0CgYREUmjYBARkTQKBhERSaNgEBGRNAoGERFJo2AQEZE0CgYREUmjYBARkTQKBhER\nSaNgEBGRNAoGERFJo2AQEZE0CgYREUmjYBARkTQKBhERSZP1YDCz/mb2BzNbYmY1ZjayyetjzWyd\nmS1KPa7Ndk0iItKyXLQYbgUed/eDgEOBJRnOed7dR6Qe1+egpqyprKwMu4R2UZ3dKx/qzIcaQXVG\nQVaDwcz6AaPdfQaAu29x948znZrNOnIpX/6xqM7ulQ915kONoDqjINsthn2ANWY2I3WbaJqZ7Zjh\nvCPMrNrMHjOzg7Nck4iItCLbwdAbGAH82t1HAHXAD5ucUwUMdvcS4FfAI1muSUREWmHunr2Lmw0A\n/uHuxannRwM/cPdTWvma5UCpu69tcjx7hYqI9GDu3qHb9b2zVQiAu79nZqvMbKi71wJfBl5rfI6Z\nDXD391KfH04QVmszXKvH9EOIiERZVoMh5TvAfWbWB1gGTDSzcsDdfRpwppldAmwGNgITclCTiIi0\nIKu3kkREJP/kxcxnMzvRzF43s1oz+0HY9WRiZoPM7NnUJL5XzOw7YdfUEjOLpUaJzQ27lpa0NTEy\nKszs6lR9L5vZfWa2Xdg1AZjZXWb2npm93OjYLmb2pJktNbO/mln/MGtM1ZSpzhtTf+/VZjY7New9\nVJnqbPTa98wsaWa7hlFbk1oy1mlmV6T+TF8xsxvauk7kg8HMYgSjlU4AhgFnm9mB4VaV0RbgSncf\nBhwBXBbROgEm06SvJ4LaMzEyVGa2N3AREHf34QS3Zs8Kt6qtZhD8zDT2Q+Bpdz8AeBa4OudVNZep\nzieBYamRim8Q3Toxs0HAccDKnFeUWbM6zawMOAU4xN0PAX7Z1kUiHwzA4cAb7r7S3TcDDwKnhlxT\nM+7+rrtXpz7/hOA/soHhVtVc6h/yycCdYdfSkg5MjAzbx8AmYCcz6w0UAe+EW1LA3ecDHzY5fCow\nM/X5TOC0nBaVQaY63f1pd0+mni4ABuW8sCZa+PME+F/gqhyX06IW6rwEuMHdt6TOWdPWdfIhGAYC\nqxo9f5sI/ofbmJkNAUqAheFWklHDP+Qody61d2JkqNz9Q+Am4F/AamCduz8dblWt+kLDCEB3fxf4\nQsj1tMck4C9hF5GJmY0HVrn7K2HX0oahwBgzW2Bmz5nZYW19QT4EQ14xs77Aw8DkVMshMszsK8B7\nqZaNEd2lSNozMTJ0ZlYMfBfYG9gT6Gtm54RbVYdE+ZcDzOw/gc3ufn/YtTSV+kXlGmBK48MhldOW\n3sAu7j4K+D7wUFtfkA/BsBoY3Oj5oNSxyEndTngYuNfd/xR2PRkcBYw3s2XAA8AxZnZPyDVl8jbB\nb2L/TD1/mCAoouYw4O/uvtbd64E5wJEh19Sa91KTTjGzPYD3Q66nRWZ2IcEtz6gG7b7AEGBxalLu\nIKDKzKLYCltF8G8Td38JSJrZ51v7gnwIhpeA/cxs79SIj7OAqI6mmQ685u63hl1IJu5+jbsPTs1E\nPwt41t0vCLuuplK3O1aZ2dDUoWYTIyNiKTDKzHYwMyOoM0qd5E1bhXOBC1OffwOIyi8vaXWa2YkE\ntzvHu/tnoVXV3NY63f1Vd9/D3YvdfR+CX2bi7h6FsG369/4IMA4g9TPVx93/3doFIh8Mqd/ELicY\nqVADPOjuUfrhA8DMjgLOBcaZWSJ1b/zEsOvKYw0TI6sJRiX9T8j1NOPui4F7CNb7Wkzwwzgt1KJS\nzOx+4AVgqJn9y8wmAjcAx5nZUoIQa3PYYra1UOftQF/gqdTP0W9CLZIW62zMicCtpBbqnA4Um9kr\nwP1Am78MaoKbiIikiXyLQUREckvBICIiaRQMIiKSRsEgIiJpFAwiIpJGwSAiImkUDFJwzGx+6uPe\nZnZ2N1/76ibP53fn9UVyQfMYpGClliP+Xmt7kGf4ml6pSZctvb7e3XfujvpEwqIWgxQcM1uf+vRn\nwNGp2bWTUxsY3WhmC1ObxFyUOn+smT1vZn8imH2Pmf3RzF5KbXzyrdSxnwE7pq53b5P3wsx+kTp/\nsZl9vdG1n7NtmxLdm7s/CZHMcrHns0jUNDSTf0jQYhgPkAqCde4+MrUu19/N7MnUuXGCzWP+lXo+\n0d3XmdkOwEtmNtvdrzazy1Irwqa9l5mdAQx390NSC629ZGbzUueUAAcD76be80h3fyFL37tIm9Ri\nENnmeOACM0sQ7KWxK7B/6rUXG4UCQEVqHaeGjWT2p3VHEaxoS2qhtUrgS42u/f89uK9bTbBqp0ho\n1GIQ2cZ6eS34AAAA6UlEQVSAK9z9qbSDZmOBDU2ejwNGuvtnZvYcsEOja7T3vRo0XkG0Hv1cSsjU\nYpBC1PCf8nqgcUfxX4FLU/tqYGb7m1lRhq/vD3yYCoUDgVGNXtvU8PVN3utvwIRUP8buwGjgxW74\nXkS6nX4zkULU0MfwMsGmJQngbne/NbUt66LU/grvk3lf5CeAi82shmBPhn80em0a8LKZVbn7+Q3v\n5e5/NLNRBMtzJ4Gr3P19MzuohdpEQqPhqiIikka3kkREJI2CQURE0igYREQkjYJBRETSKBhERCSN\ngkFERNIoGEREJI2CQURE0vwf/dcy45LXZLMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1073e0438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(logistic, gradient_logistic, nll, theta, .1, D, .01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.529066\n",
      "truth=-1  pr(true label)=0.306266\n",
      "truth=-1  pr(true label)=0.306266\n",
      "truth=-1  pr(true label)=0.470934\n",
      "truth=1  pr(true label)=0.693734\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.331537\n",
      "old error=8.70686   new error=6.61226  theta=[ 0.11639329  0.70124015]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.501232\n",
      "truth=-1  pr(true label)=0.28773\n",
      "truth=-1  pr(true label)=0.28773\n",
      "truth=-1  pr(true label)=0.498768\n",
      "truth=1  pr(true label)=0.71227\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.28874\n",
      "old error=6.61226   new error=6.84559  theta=[ 0.00492745  0.901509  ]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00492745,  0.901509  ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Uz0dBdyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10581d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What if learning rate too big?\n",
    "theta = npa([1.,1.])\n",
    "gradient_descent(logistic, gradient_logistic, nll, theta, .8, D, .01, 50)\n",
    "# We stop too early!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i) + \\lambda \\sum_k \\theta_k^2\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
