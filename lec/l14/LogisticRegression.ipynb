{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 14: Logistic Regression\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall classification problem notation:\n",
    "\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email\n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=-1$: not spam\n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training data:**\n",
    "\n",
    "We are given training data $D = \\{(\\vec{x}_1, y_1), \\ldots, (\\vec{x}_n, y_n)\\}$\n",
    "\n",
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n",
    "\n",
    "How to classify a new instance?  \n",
    " \"free money\" -> $\\{1,1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall Naive Bayes:**\n",
    "\n",
    "$p(y|\\vec{x}) = \\frac{p(\\vec{x}|y)p(y)}{p(\\vec{x})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Recall gradient descent recipe **\n",
    "\n",
    "1.  Select a model type (e.g., linear classification, logistic classification)\n",
    "\n",
    "2.  Select an <span>**error function**</span> that, when minimized, results in a good setting of the model parameters.\n",
    "\n",
    "3.  Analytically determine the gradient of the error function with respect to the model parameters.\n",
    "\n",
    "4.  Iteratively change the parameters by a small amount in the direction of the gradient until the (near) minimum of the error function is found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we considered a simple linear model with two parameters:\n",
    "\n",
    "$h(x_i) = mx_i + b$\n",
    "\n",
    "This assumes only a single feature (term). \n",
    "\n",
    "Instead, we make $x_i$ a vector $\\vec{x_i}$ containing values for $v$ terms: $\\vec{x_i} = \\{x_{i1} \\ldots x_{iv}\\}$, which has a corresponding vector of parameters $\\vec{\\theta}$.\n",
    "\n",
    "$$ h(\\vec{x}_i) = \\vec{x}_i^T  {\\theta} = x_{i1} \\theta_1 + \\ldots x_{iv} \\theta_v = \\sum_j x_{ij}{\\theta}_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array as npa\n",
    "import numpy as np\n",
    "\n",
    "def h(x, theta):\n",
    "    return np.dot(x.T, theta)\n",
    "\n",
    "x = npa([1,2,3])  # term0 appears 1 time, term1 appears 2 times...\n",
    "theta = npa([-1, -1, 5])  # term 2 predictive of positive class\n",
    "h(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a negative example.\n",
    "x2 = npa([10, 10, 0])\n",
    "h(x2, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given training data $D$, how do we pick $\\vec{\\theta}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the gradient descent recipe, we need an error function:\n",
    "\n",
    "*Residual Sum of Squares*\n",
    "\n",
    "$$\n",
    "RSS(\\theta, D) = \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - h(\\vec{x}_i, \\vec{\\theta}))^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss(theta, D):\n",
    "    error = 0\n",
    "    for xi, yi in D:\n",
    "        prediction = h(xi, theta)\n",
    "        errori = (yi - prediction)**2\n",
    "        error += errori\n",
    "        #print('truth=%g  prediction=%g error=%g' % (yi, prediction, errori))\n",
    "    return error / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "\n",
      "RSS=4\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    (npa([0,0]), -1),\n",
    "    (npa([1,0]), 1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,0]), -1),\n",
    "    (npa([1,1]), 1),\n",
    "    (npa([0,0]), 1),\n",
    "    (npa([0,1]), -1),\n",
    "]\n",
    "theta = npa([0,0])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "RSS=14.5\n"
     ]
    }
   ],
   "source": [
    "theta = npa([1,1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=0.5 error=2.25\n",
      "truth=1  prediction=-0.5 error=2.25\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-1 error=0\n",
      "\n",
      "RSS=3.625\n"
     ]
    }
   ],
   "source": [
    "theta = npa([0.5,-1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Pick optimal $\\vec{\\theta}^*$ to satisfy:\n",
    "\n",
    "$$ \\vec{\\theta}^*: argmin_\\vec{\\theta} \\hspace{.4cm} RSS(\\vec{\\theta}, D)$$\n",
    "\n",
    "**Solution:** Gradient descent\n",
    "\n",
    "while not converged:\n",
    "1. Compute gradient $\\nabla_\\vec{\\theta}$ of $\\vec{\\theta}$ w.r.t. RSS\n",
    "2. Change $\\vec{\\theta}$ in direction of $\\nabla_\\vec{\\theta}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_\\vec{\\theta} = \\{\\frac{\\partial RSS(\\vec{\\theta}, D)}{\\partial \\theta_1} \\ldots \\frac{\\partial RSS(\\vec{\\theta}, D)}{\\partial \\theta_v}\\}$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial RSS(\\vec{\\theta}, D)}{\\partial \\theta_j} &=& \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)\\frac{\\partial}{\\partial \\theta_j} (y_i - \\theta \\cdot \\vec{x}_i)\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)(-x_{ij})\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To update parameters:**\n",
    "\n",
    "$${\\vec{\\theta}}^{t+1}_j = \\vec{\\theta}_j^{t} - \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "$\\eta$ = \"learning rate\", to prevent \"jumping over\" minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        error = yi - h(xi, theta)\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * -xij# learning rate is 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(npa([0,0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-1 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-1 error=0\n",
      "truth=1  prediction=-3 error=16\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-2 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([-1, -2]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient_descent(h_fn, gradient_fn, error_fn, theta,\n",
    "                     learning_rate, D, tolerance, max_iters):\n",
    "    errori = error_fn(theta, D)\n",
    "    iters = 0\n",
    "    all_errors = [errori]\n",
    "    while True:\n",
    "        iters += 1\n",
    "        print('\\n\\niteration %d' % iters)\n",
    "        grad = gradient_fn(theta, D)\n",
    "        theta -= learning_rate * grad  # UPDATE!\n",
    "        newerror = error_fn(theta, D)\n",
    "        all_errors.append(newerror)\n",
    "        print('old error=%g   new error=%g  theta=%s\\n\\n' %\n",
    "              (errori, newerror, str(theta)))\n",
    "        error_diff = errori - newerror\n",
    "        if error_diff < 0 or errori - newerror < tolerance \\\n",
    "            or iters >= max_iters:\n",
    "            break\n",
    "        else:\n",
    "            errori = newerror\n",
    "            \n",
    "    plt.plot(all_errors, 'bo-')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('error')\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iteration 1\n",
      "old error=14.5   new error=6.4  theta=[-0.8 -0.8]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "old error=6.4   new error=4.2616  theta=[ 0.28 -0.08]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "old error=4.2616   new error=3.68618  theta=[-0.152 -0.584]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "old error=3.68618   new error=3.52599  theta=[ 0.1504 -0.4256]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "old error=3.52599   new error=3.47882  theta=[ 0.05536 -0.57536]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "old error=3.47882   new error=3.46374  theta=[ 0.145216 -0.548288]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "old error=3.46374   new error=3.45839  theta=[ 0.1289728 -0.5967872]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1289728, -0.5967872])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEPCAYAAABLIROyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVABERDLq/wPJ1boDreEhzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10514c7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(h, gradient, rss, theta, .2, D, .01, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does our error function make sense?**\n",
    "\n",
    "\n",
    "iteration 1  \n",
    "truth=-1  prediction=0 error=1  \n",
    "truth=1  prediction=-0.8 error=3.24  \n",
    "**truth=-1  prediction=-1.6 error=0.36**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above assumes that the output variable $y_i$ is a real number. Thus, this is a model of <span>**regression**</span>.  \n",
    "\n",
    "When $y$ is disrete, the problem is one of <span>**classification**</span>.  \n",
    "\n",
    "One could use the linear model above to do classification. Assume the binary case where $y_i$ can either be $-1$ or $1$. We can convert the regression model to a classifier by assuming that if the model outputs a number greater than 0, then predict 1; otherwise, predict -1.\n",
    "\n",
    "However, this can cause weird things to happen in our update rule: \n",
    "\n",
    "$$\\vec{\\theta}_j^{t+1} = \\vec{\\theta}_j^{t} + \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "\n",
    "Suppose the true value of $y_1$ is $1$, and the model (dot product) returns 2. The instance is technically classified correctly, but the update still counts this as an error of size 1 (since $y_i -\\theta \\cdot x_i$ is 1). In fact, the update considers this error equivalent to a dot product of $0$, which would in fact result in a classification error.\n",
    "\n",
    "This is clearly not what we want – in fact, our gradient descent algorithm may never converge, since we can always make our correct classifications “more correct” by cranking up the value of $\\theta$.\n",
    "\n",
    "The way around this is to change our model. Rather than regression, we need classification. We can do this by passing the dot product $x_i \\cdot \\theta$ through a “squashing function” (the **logistic function**) that ensures its value is always between 0 and 1: \n",
    "\n",
    "$$h(\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "This is called **logistic regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nROpRMIiISD0KBhERqUfBICIi9fx/EZym4DL7jnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105e36470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import exp\n",
    "def logistic(x, theta):\n",
    "    return 1 / (1 + exp(-h(x, theta)))\n",
    "    \n",
    "x = npa([1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(-10, 10), [logistic(x, theta) for theta in range(-10, 10)])\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('logistic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $h(x_i)$ will always be between 0 and 1, and will sum to one for both classes, we have the right to call this a <span>**probability**</span> $p(y_i=1|\\vec{x}_i)$.  \n",
    "\n",
    "$$h(\\vec{x}_i) = p(y_i=1|\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "and, for binary classification, the probability of a negative example:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = 1 - p(y_i=1|\\vec{x}_i)\n",
    "$$\n",
    "\n",
    "with some algebra, it turns out that:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = \\frac{1}{1 + e^{\\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$\n",
    "\n",
    "Because of this, if $y_i \\in \\{-1, 1\\}$, we can write:\n",
    "\n",
    "$$\n",
    "p(y_i|\\vec{x}_i) =  \\frac{1}{1 + e^{-y_i \\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a good error function for logistic regression?**\n",
    "\n",
    "We can now rephrase our learning objective as maximizing the <span>*joint probability of the true labels for all training instances.*</span>  \n",
    "\n",
    "Since we assume each instance is drawn independently, we can write this joint probability as a product of individual probabilities: \n",
    "\n",
    "$$p(y_1 \\ldots y_n|\\vec{x}_1 \\ldots \\vec{x}_n) = p(y_1|\\vec{x}_1) * p(y_2|\\vec{x}_2) * \\ldots * p(y_n|\\vec{x}_n) = \\prod_{i=1}^{n}p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "Because we’re used to minimizing functions using gradient descent, rather than maximizing the probability, we can instead minimize the negative probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i)\n",
    "$$\n",
    "\n",
    "Note that this is very similar to RSS, but by using probabilities, we ensure that the output for each instance is always between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following our learning recipe, our next step is to minimize $E(D,h)$ using gradient descent.  \n",
    "\n",
    "Computing the gradient of $E(D,h)$ in its current form is rather hard. So, we can simply transform it to something that’s easier to take the gradient of: \n",
    "\n",
    "$$E(D,h) = - \\ln \\prod_{i=1}^n  p(y_i|\\vec{x}_i) = -\\sum_i \\ln p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "This is called the <span>**negative log likelihood**</span>. It turns out that minimizing f(x) or ln f(x) results in the same answer, so we can make this transformation without affecting our final solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def nll(theta, D):\n",
    "    total = 0\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        print('truth=%g  pr(true label)=%g' % (yi, pred))\n",
    "        total += log(pred)\n",
    "    return -total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we’re ready to calculate the gradient with respect to one parameter $\\theta_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E(D,h)}{\\partial \\theta_j} & =  \\frac{\\partial}{\\partial \\theta_j}- \\ln \\prod_i \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\\\\n",
    "& =   \\frac{\\partial}{\\partial \\theta_j}-  \\sum_i \\ln \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{(by definition of log of products)}\\\\\n",
    "& =   -  \\sum_i 1 + e^{-y_i x_i \\cdot \\theta} \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad  \\hbox{  (by }\\frac{d}{dx}\\ln(f(x)) = \\frac{1}{f(x)} \\frac{d}{dx}f(x) ) \\\\\n",
    "& =   -  \\sum_i (1 + e^{-y_i x_i \\cdot \\theta})\\Big(\\frac{-y_ix_{ij} e^{-y_ix_i \\cdot \\theta}}{(1 + e^{-y_ix_i\\cdot \\theta})^2}\\Big) \\quad \\hbox{    (by quotient and chain rules) }\\\\\n",
    "& =  - \\sum_i \\frac{-y_i x_{ij} e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{     (by algebra) }\\\\\n",
    "& =  \\sum_i y_i x_{ij} (1 - p(y_i | x_i)) \\quad \\Big( \\hbox{by }\\frac{e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} = 1 - p(y_i|x_i) \\Big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the final logistic regression update is: \n",
    "\n",
    "$$\n",
    "\\vec{\\theta}_j^{t+1} \\leftarrow \\vec{\\theta}_j^{t} + \\eta \\sum_i y_i x_{ij}(1-p(y_i|\\vec{x}_i))\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_logistic(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        error = yi * pred\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.708797\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.135614\n",
      "truth=-1  pr(true label)=0.291203\n",
      "truth=1  pr(true label)=0.864386\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.276347\n",
      "old error=8.70686   new error=8.39193  theta=[ 0.88954916  0.96265502]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.687504\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.151942\n",
      "truth=-1  pr(true label)=0.312496\n",
      "truth=1  pr(true label)=0.848058\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.282727\n",
      "old error=8.39193   new error=8.12073  theta=[ 0.78847403  0.930974  ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.667424\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.167788\n",
      "truth=-1  pr(true label)=0.332576\n",
      "truth=1  pr(true label)=0.832212\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.288059\n",
      "old error=8.12073   new error=7.88988  theta=[ 0.69655599  0.9048294 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.648718\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.182817\n",
      "truth=-1  pr(true label)=0.351282\n",
      "truth=1  pr(true label)=0.817183\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292355\n",
      "old error=7.88988   new error=7.69544  theta=[ 0.61340767  0.88397173]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.631466\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.196777\n",
      "truth=-1  pr(true label)=0.368534\n",
      "truth=1  pr(true label)=0.803223\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.29566\n",
      "old error=7.69544   new error=7.53326  theta=[ 0.53850913  0.86805228]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.615679\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.209507\n",
      "truth=-1  pr(true label)=0.384321\n",
      "truth=1  pr(true label)=0.790493\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.298039\n",
      "old error=7.53326   new error=7.39923  theta=[ 0.47124912  0.85665135]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.601319\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.220927\n",
      "truth=-1  pr(true label)=0.398681\n",
      "truth=1  pr(true label)=0.779073\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299578\n",
      "old error=7.39923   new error=7.28939  theta=[ 0.4109653   0.84930736]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 8\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.588309\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.231027\n",
      "truth=-1  pr(true label)=0.411691\n",
      "truth=1  pr(true label)=0.768973\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300369\n",
      "old error=7.28939   new error=7.20017  theta=[ 0.35697953  0.84554326]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 9\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.57655\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.239848\n",
      "truth=-1  pr(true label)=0.42345\n",
      "truth=1  pr(true label)=0.760152\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300506\n",
      "old error=7.20017   new error=7.12833  theta=[ 0.30862573  0.84488814]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 10\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.565931\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.247468\n",
      "truth=-1  pr(true label)=0.434069\n",
      "truth=1  pr(true label)=0.752532\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.300085\n",
      "old error=7.12833   new error=7.07108  theta=[ 0.26527013  0.84689312]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 11\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.556341\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.253986\n",
      "truth=-1  pr(true label)=0.443659\n",
      "truth=1  pr(true label)=0.746014\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.299193\n",
      "old error=7.07108   new error=7.026  theta=[ 0.2263242   0.85114197]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 12\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.547668\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.259512\n",
      "truth=-1  pr(true label)=0.452332\n",
      "truth=1  pr(true label)=0.740488\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.297913\n",
      "old error=7.026   new error=6.99103  theta=[ 0.19125179  0.85725705]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 13\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.539808\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.264157\n",
      "truth=-1  pr(true label)=0.460192\n",
      "truth=1  pr(true label)=0.735843\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.296316\n",
      "old error=6.99103   new error=6.96444  theta=[ 0.15957171  0.86490179]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 14\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.532668\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.268031\n",
      "truth=-1  pr(true label)=0.467332\n",
      "truth=1  pr(true label)=0.731969\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.294468\n",
      "old error=6.96444   new error=6.94478  theta=[ 0.13085709  0.87378049]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 15\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.526159\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.271234\n",
      "truth=-1  pr(true label)=0.473841\n",
      "truth=1  pr(true label)=0.728766\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.292425\n",
      "old error=6.94478   new error=6.93083  theta=[ 0.10473274  0.8836365 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 16\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.520207\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.273861\n",
      "truth=-1  pr(true label)=0.479793\n",
      "truth=1  pr(true label)=0.726139\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.290234\n",
      "old error=6.93083   new error=6.92157  theta=[ 0.08087117  0.89424926]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.08087117,  0.89424926])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngkFERNIoGEREJI2CQURE0vwf/dcy45LXZLMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1073e0438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(logistic, gradient_logistic, nll, theta, .1, D, .01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.529066\n",
      "truth=-1  pr(true label)=0.306266\n",
      "truth=-1  pr(true label)=0.306266\n",
      "truth=-1  pr(true label)=0.470934\n",
      "truth=1  pr(true label)=0.693734\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.331537\n",
      "old error=8.70686   new error=6.61226  theta=[ 0.11639329  0.70124015]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.501232\n",
      "truth=-1  pr(true label)=0.28773\n",
      "truth=-1  pr(true label)=0.28773\n",
      "truth=-1  pr(true label)=0.498768\n",
      "truth=1  pr(true label)=0.71227\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.28874\n",
      "old error=6.61226   new error=6.84559  theta=[ 0.00492745  0.901509  ]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00492745,  0.901509  ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4Uz0dBdyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10581d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What if learning rate too big?\n",
    "theta = npa([1.,1.])\n",
    "gradient_descent(logistic, gradient_logistic, nll, theta, .8, D, .01, 50)\n",
    "# We stop too early!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i) + \\lambda \\sum_k \\theta_k^2\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
