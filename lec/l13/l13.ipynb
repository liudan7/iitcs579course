{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579: Lecture 13  \n",
    "\n",
    "**Demographic Inference II**\n",
    "\n",
    "*[Dr. Aron Culotta](http://cs.iit.edu/~culotta)*  \n",
    "*[Illinois Institute of Technology](http://iit.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Classification\n",
    "\n",
    "Let's build a classifier to predict whether a Twitter user is male/female.\n",
    "\n",
    "We'll collect \"labeled\" training data using Census name list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.) Collect Census names. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1146 female and 4014 male names\n",
      "male name sample: ['lemuel', 'loren', 'luciano', 'ernesto', 'frank']\n",
      "female name sample: ['delaine', 'maye', 'cristie', 'alyssa', 'felica']\n"
     ]
    }
   ],
   "source": [
    "# Fetch male/female names from Census.\n",
    "\n",
    "import requests\n",
    "\n",
    "def get_census_names():\n",
    "    \"\"\" Fetch a list of common male/female names from the census.\n",
    "    For ambiguous names, we select the more frequent gender.\"\"\"\n",
    "    males = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.male.first').text.split('\\n')\n",
    "    females = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.female.first').text.split('\\n')\n",
    "    males_pct = dict([(m.split()[0].lower(), float(m.split()[1]))\n",
    "                  for m in males if m])\n",
    "    females_pct = dict([(f.split()[0].lower(), float(f.split()[1]))\n",
    "                    for f in females if f])\n",
    "    male_names = set([m for m in males_pct if m not in females_pct or\n",
    "                  males_pct[m] > females_pct[m]])\n",
    "    female_names = set([f for f in females_pct if f not in males_pct or\n",
    "                  females_pct[f] > males_pct[f]])    \n",
    "    return male_names, female_names\n",
    "\n",
    "male_names, female_names = get_census_names()\n",
    "print('found %d female and %d male names' % (len(male_names), len(female_names)))\n",
    "print('male name sample:', list(male_names)[:5])\n",
    "print('female name sample:', list(female_names)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.) Sample 5K tweets with names on the Census list. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct TwitterAPI object.\n",
    "\n",
    "import configparser\n",
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "def get_twitter(config_file):\n",
    "    \"\"\" Read the config_file and construct an instance of TwitterAPI.\n",
    "    Args:\n",
    "      config_file ... A config file in ConfigParser format with Twitter credentials\n",
    "    Returns:\n",
    "      An instance of TwitterAPI.\n",
    "    \"\"\"\n",
    "    #config = configparser.ConfigParser()\n",
    "    #config.read(config_file)\n",
    "    #twitter = TwitterAPI(\n",
    "    #               config.get('twitter', 'consumer_key'),\n",
    "    #               config.get('twitter', 'consumer_secret'),\n",
    "    #               config.get('twitter', 'access_token'),\n",
    "    #               config.get('twitter', 'access_token_secret'))\n",
    "    \n",
    "    #my info\n",
    "    consumer_key = 'Q6sCDic9j8mNMhZB2BysN69vr'\n",
    "    consumer_secret = 'FdaQjrFThC0F3xddTZ1WnwhNmCtw08es0X1EIMCloQmOfxUc47'\n",
    "    access_token = '3584891536-Lm7t8eHMyf9l0MDXVdXwL4gj2xKZJ6EHzxp85ev'\n",
    "    access_token_secret = 'cajDlqGO2ExbHh0cRLK4WOyzw1i5E7Q4EIIi4qe99EoG2'\n",
    "    twitter = TwitterAPI(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "    return twitter\n",
    "\n",
    "\n",
    "twitter = get_twitter('twitter.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100 tweets\n",
      "found 200 tweets\n",
      "found 300 tweets\n",
      "found 400 tweets\n",
      "found 500 tweets\n",
      "found 600 tweets\n",
      "found 700 tweets\n",
      "found 800 tweets\n",
      "found 900 tweets\n",
      "found 1000 tweets\n",
      "found 1100 tweets\n",
      "found 1200 tweets\n",
      "found 1300 tweets\n",
      "found 1400 tweets\n",
      "found 1500 tweets\n",
      "found 1600 tweets\n",
      "found 1700 tweets\n",
      "found 1800 tweets\n",
      "found 1900 tweets\n",
      "found 2000 tweets\n",
      "found 2100 tweets\n",
      "found 2200 tweets\n",
      "found 2300 tweets\n",
      "found 2400 tweets\n",
      "found 2500 tweets\n",
      "found 2600 tweets\n",
      "found 2700 tweets\n",
      "found 2800 tweets\n",
      "found 2900 tweets\n",
      "found 3000 tweets\n",
      "found 3100 tweets\n",
      "found 3200 tweets\n",
      "found 3300 tweets\n",
      "found 3400 tweets\n",
      "found 3500 tweets\n",
      "found 3600 tweets\n",
      "found 3700 tweets\n",
      "found 3800 tweets\n",
      "found 3900 tweets\n",
      "found 4000 tweets\n",
      "found 4100 tweets\n",
      "found 4200 tweets\n",
      "found 4300 tweets\n",
      "found 4400 tweets\n",
      "found 4500 tweets\n",
      "found 4600 tweets\n",
      "found 4700 tweets\n",
      "found 4800 tweets\n",
      "found 4900 tweets\n",
      "found 5000 tweets\n"
     ]
    }
   ],
   "source": [
    "# Sample U.S. tweets with names from Census. \n",
    "import sys\n",
    "\n",
    "def get_first_name(tweet):\n",
    "    if 'user' in tweet and 'name' in tweet['user']:\n",
    "        parts = tweet['user']['name'].split()\n",
    "        if len(parts) > 0:\n",
    "            return parts[0].lower()\n",
    "\n",
    "def sample_tweets(twitter, limit, male_names, female_names):\n",
    "    tweets = []\n",
    "    while True:\n",
    "        try:\n",
    "            # Restrict to U.S.\n",
    "            for response in twitter.request('statuses/filter',\n",
    "                        {'locations':'-124.637,24.548,-66.993,48.9974'}):\n",
    "                if 'user' in response:\n",
    "                    name = get_first_name(response)\n",
    "                    if name in male_names or name in female_names:# get the names in our census list\n",
    "                        tweets.append(response)\n",
    "                        if len(tweets) % 100 == 0:\n",
    "                            print('found %d tweets' % len(tweets))\n",
    "                        if len(tweets) >= limit:\n",
    "                            return tweets\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    return tweets\n",
    "        \n",
    "tweets = sample_tweets(twitter, 5000, male_names, female_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled 5000 tweets\n",
      "top names: [('mike', 59), ('john', 50), ('chris', 46), ('james', 41), ('matt', 37), ('david', 37), ('king', 36), ('katie', 34), ('michael', 34), ('mark', 32)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('sampled %d tweets' % len(tweets))\n",
    "print('top names:', Counter(get_first_name(t) for t in tweets).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save these tweets.\n",
    "import pickle\n",
    "pickle.dump(tweets, open('tweets.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.) Tokenize tweets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test tweet:\n",
      "\tscreen_name=thompsontroy\n",
      "\tname=troy thompson\n",
      "\tdescr=Love that grace, struggling sinner/saint, lover of all peoples, follower of a Lamb, teller of hope, believer of miracles, provider of rest to the ugly birds!\n",
      "\ttext=Merry Christmas from precious_._thompson! #christmas #northcoast @ Church on the North Coast https://t.co/HBXTwiE1Wc\n"
     ]
    }
   ],
   "source": [
    "test_tweet = tweets[201]\n",
    "print('test tweet:\\n\\tscreen_name=%s\\n\\tname=%s\\n\\tdescr=%s\\n\\ttext=%s' %\n",
    "      (test_tweet['user']['screen_name'],\n",
    "       test_tweet['user']['name'],\n",
    "       test_tweet['user']['description'],\n",
    "       test_tweet['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(string, lowercase, keep_punctuation, prefix,\n",
    "             collapse_urls, collapse_mentions):\n",
    "    \"\"\" Split a tweet into tokens.\"\"\"\n",
    "    if not string:\n",
    "        return []\n",
    "    if lowercase:\n",
    "        string = string.lower()\n",
    "    tokens = []\n",
    "    if collapse_urls:\n",
    "        string = re.sub('http\\S+', 'THIS_IS_A_URL', string)\n",
    "    if collapse_mentions:\n",
    "        string = re.sub('@\\S+', 'THIS_IS_A_MENTION', string)\n",
    "    if keep_punctuation:\n",
    "        tokens = string.split()\n",
    "    else:\n",
    "        tokens = re.sub('\\W+', ' ', string).split()\n",
    "    if prefix:\n",
    "        tokens = ['%s%s' % (prefix, t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d=love',\n",
       " 'd=that',\n",
       " 'd=grace,',\n",
       " 'd=struggling',\n",
       " 'd=sinner/saint,',\n",
       " 'd=lover',\n",
       " 'd=of',\n",
       " 'd=all',\n",
       " 'd=peoples,',\n",
       " 'd=follower',\n",
       " 'd=of',\n",
       " 'd=a',\n",
       " 'd=lamb,',\n",
       " 'd=teller',\n",
       " 'd=of',\n",
       " 'd=hope,',\n",
       " 'd=believer',\n",
       " 'd=of',\n",
       " 'd=miracles,',\n",
       " 'd=provider',\n",
       " 'd=of',\n",
       " 'd=rest',\n",
       " 'd=to',\n",
       " 'd=the',\n",
       " 'd=ugly',\n",
       " 'd=birds!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(test_tweet['user']['description'], lowercase=True,\n",
    "         keep_punctuation=True, prefix='d=',\n",
    "         collapse_urls=True, collapse_mentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t=merry',\n",
       " 't=christmas',\n",
       " 't=from',\n",
       " 't=precious_._thompson!',\n",
       " 't=#christmas',\n",
       " 't=#northcoast',\n",
       " 't=@',\n",
       " 't=church',\n",
       " 't=on',\n",
       " 't=the',\n",
       " 't=north',\n",
       " 't=coast',\n",
       " 't=THIS_IS_A_URL']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(test_tweet['text'], lowercase=True, keep_punctuation=True,\n",
    "         prefix='t=',\n",
    "         collapse_urls=True, collapse_mentions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet2tokens(tweet, use_descr=True, lowercase=True,\n",
    "                 keep_punctuation=True, descr_prefix='d=',\n",
    "                 collapse_urls=True, collapse_mentions=True):\n",
    "    \"\"\" Convert a tweet into a list of tokens, from the tweet text and optionally the\n",
    "    user description. \"\"\"\n",
    "    tokens = tokenize(tweet['text'], lowercase, keep_punctuation, None,\n",
    "                       collapse_urls, collapse_mentions)\n",
    "    if use_descr:\n",
    "        tokens.extend(tokenize(tweet['user']['description'], lowercase,\n",
    "                               keep_punctuation, descr_prefix,\n",
    "                               collapse_urls, collapse_mentions))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc  d=love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc  d=love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL  love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL  love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc  love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc  love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc  d=love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc  d=love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL  love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL  love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc  love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc  love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL  d=Love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=Lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL  d=Love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=Lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc  d=Love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=Lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc  d=Love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=Lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL  Love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  Lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL  Love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  Lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc  Love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  Lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc  Love  that  grace,  struggling  sinner/saint,  lover  of  all  peoples,  follower  of  a  Lamb,  teller  of  hope,  believer  of  miracles,  provider  of  rest  to  the  ugly  birds! \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL  d=Love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=Lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL  d=Love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=Lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc  d=Love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=Lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc  d=Love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=Lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL  Love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  Lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL  Love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  Lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc  Love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  Lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=True  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc  Love  that  grace  struggling  sinner  saint  lover  of  all  peoples  follower  of  a  Lamb  teller  of  hope  believer  of  miracles  provider  of  rest  to  the  ugly  birds \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  https://t.co/hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  https  t  co  hbxtwie1wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_._thompson!  #christmas  #northcoast  @  Church  on  the  North  Coast  https://t.co/HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  THIS_IS_A_URL \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc \n",
      "----\n",
      "\n",
      "use_descr=False  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "Merry  Christmas  from  precious_  _thompson  christmas  northcoast  Church  on  the  North  Coast  https  t  co  HBXTwiE1Wc \n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for enumerating all possible arguments of tweet2tokens\n",
    "# https://docs.python.org/2/library/itertools.html#itertools.product\n",
    "from itertools import product\n",
    "\n",
    "use_descr_opts = [True, False]\n",
    "lowercase_opts = [True, False]\n",
    "keep_punctuation_opts = [True, False]\n",
    "descr_prefix_opts = ['d=', '']\n",
    "url_opts = [True, False]\n",
    "mention_opts = [True, False]\n",
    "\n",
    "argnames = ['use_descr', 'lower', 'punct', 'prefix', 'url', 'mention']\n",
    "option_iter = product(use_descr_opts, lowercase_opts,\n",
    "                       keep_punctuation_opts,\n",
    "                       descr_prefix_opts, url_opts,\n",
    "                       mention_opts)\n",
    "for options in option_iter:\n",
    "    print('  '.join('%s=%s' % (name, opt) for name, opt in zip(argnames, options)))\n",
    "    print\n",
    "    print('  '.join(tweet2tokens(test_tweet, *options)), '\\n----\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's tokenize all tweets.\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=False, descr_prefix='d=',\n",
    "                            collapse_urls=True, collapse_mentions=True)\n",
    "              for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['merry',\n",
       " 'christmas',\n",
       " 'from',\n",
       " 'precious_',\n",
       " '_thompson',\n",
       " 'christmas',\n",
       " 'northcoast',\n",
       " 'church',\n",
       " 'on',\n",
       " 'the',\n",
       " 'north',\n",
       " 'coast',\n",
       " 'THIS_IS_A_URL',\n",
       " 'd=love',\n",
       " 'd=that',\n",
       " 'd=grace',\n",
       " 'd=struggling',\n",
       " 'd=sinner',\n",
       " 'd=saint',\n",
       " 'd=lover',\n",
       " 'd=of',\n",
       " 'd=all',\n",
       " 'd=peoples',\n",
       " 'd=follower',\n",
       " 'd=of',\n",
       " 'd=a',\n",
       " 'd=lamb',\n",
       " 'd=teller',\n",
       " 'd=of',\n",
       " 'd=hope',\n",
       " 'd=believer',\n",
       " 'd=of',\n",
       " 'd=miracles',\n",
       " 'd=provider',\n",
       " 'd=of',\n",
       " 'd=rest',\n",
       " 'd=to',\n",
       " 'd=the',\n",
       " 'd=ugly',\n",
       " 'd=birds']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_list[201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store these in a sparse matrix.\n",
    "\n",
    "#1) Create a vocabulary (dict from term->index)\n",
    "\n",
    "# https://docs.python.org/2/library/collections.html#collections.defaultdict\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_vocabulary(tokens_list):\n",
    "    vocabulary = defaultdict(lambda: len(vocabulary))  # If term not present, assign next int. \n",
    "    #just give them a one by one index\n",
    "    for tokens in tokens_list:\n",
    "        for token in tokens:\n",
    "            vocabulary[token]  # looking up a key; defaultdict takes care of assigning it a value.\n",
    "    print('%d unique terms in vocabulary' % len(vocabulary))\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19261 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d=calling', 2830),\n",
       " ('are', 158),\n",
       " ('boostmobile', 15769),\n",
       " ('d=davis', 17890),\n",
       " ('d=cocks', 14823),\n",
       " ('d=kentucky', 6595),\n",
       " ('d=woody', 6672),\n",
       " ('yazoohefeisthegreatestbeerintheknownuniverse', 11140),\n",
       " ('d=gmg', 9836),\n",
       " ('d=22', 856)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term->index\n",
    "list(vocabulary.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27237 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=True, collapse_mentions=True)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
    "\n",
    "merry  christmas  from  precious_  _thompson  christmas  northcoast  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace  d=struggling  d=sinner  d=saint  d=lover  d=of  d=all  d=peoples  d=follower  d=of  d=a  d=lamb  d=teller  d=of  d=hope  d=believer  d=of  d=miracles  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds \n",
    "\n",
    "use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
    "\n",
    "merry  christmas  from  precious_._thompson!  #christmas  #northcoast  @  church  on  the  north  coast  THIS_IS_A_URL  d=love  d=that  d=grace,  d=struggling  d=sinner/saint,  d=lover  d=of  d=all  d=peoples,  d=follower  d=of  d=a  d=lamb,  d=teller  d=of  d=hope,  d=believer  d=of  d=miracles,  d=provider  d=of  d=rest  d=to  d=the  d=ugly  d=birds! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29353 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation and urls?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=False, collapse_mentions=True)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32801 unique terms in vocabulary\n"
     ]
    }
   ],
   "source": [
    "# How big is vocabulary if we keep punctuation and urls and mentions?\n",
    "tokens_list = [tweet2tokens(t, use_descr=True, lowercase=True,\n",
    "                            keep_punctuation=True, descr_prefix='d=',\n",
    "                            collapse_urls=False, collapse_mentions=False)\n",
    "              for t in tweets]\n",
    "\n",
    "vocabulary = make_vocabulary(tokens_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vector Matrix\n",
    "\n",
    "Create a matrix $X$ where $X[i,j]$ is the frequency of term $j$ in tweet $i$.\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Matrices\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$X$ is mostly $0$ for text problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of List (LIL) Matrix\n",
    "\n",
    "Store a linked list of (index, value) pairs for each row.\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "\\hbox{tweet}_1 & (0, 1)\\\\\n",
    "\\hbox{tweet}_2 & (3,2)\\\\\n",
    "\\hbox{tweet}_3 & (0,1), (1,1)\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "**Advantage:** Fast to construct: append to list in constant time.\n",
    "\n",
    "**Disadvantage:** Slow random access for matrix-vector product.\n",
    "\n",
    "E.g., $\\hat{z} = X\\cdot \\hat{\\beta}$ to classify tweets using a learned weight vector $\\beta$\n",
    "\n",
    "$\\hat{z}[i] = \\sum_j X[i,j] * \\beta[j]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Sparse Row (CSR) Matrix\n",
    "\n",
    "\n",
    "$$\n",
    "X = \\begin{pmatrix}\n",
    "~ & \\hbox{term}_1 & \\hbox{term}_2 & \\hbox{term}_3 & \\hbox{term}_4 \\\\\n",
    "\\hbox{tweet}_1 & 1  &  0  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_2 & 0  &  0  &  0 & 2 \\\\\n",
    "\\hbox{tweet}_3 & 1  &  1  &  0 & 0 \\\\\n",
    "\\hbox{tweet}_4 & 1  &  0  &  0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "CSR Matrix is an object with three attributes: \n",
    "- **val:** $\\{1,2,1,1,1\\}$  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *list of all non-zero values*  \n",
    "- **col_ind:** $\\{0,3,0,1,0\\}$ &nbsp; *column index for each non-zero value* (e.g., first non-zero value (1) is in column 0) \n",
    "- **row_ptr:** $\\{0,1,2,4\\}$ &nbsp;&nbsp;&nbsp; *index into **col_ind** where each row starts* (e.g., tweet3, term1 corresponds to col_ind[2])\n",
    "\n",
    "Allows efficient row access (good for us, since each row is a tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert features to a sparse matrix X.\n",
    "# X[i,j] is the frequency of term j in tweet i\n",
    "# \n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def make_feature_matrix(tokens_list, vocabulary):\n",
    "    X = lil_matrix((len(tweets), len(vocabulary)))\n",
    "    for i, tokens in enumerate(tokens_list):\n",
    "        for token in tokens:\n",
    "            j = vocabulary[token]\n",
    "            X[i,j] += 1\n",
    "    return X.tocsr()  # convert to CSR for more efficient random access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (5000, 32801)\n"
     ]
    }
   ],
   "source": [
    "X = make_feature_matrix(tokens_list, vocabulary)\n",
    "print('shape of X:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on csr_matrix in module scipy.sparse.csr object:\n",
      "\n",
      "class csr_matrix(scipy.sparse.compressed._cs_matrix, scipy.sparse.sputils.IndexMixin)\n",
      " |  Compressed Sparse Row matrix\n",
      " |  \n",
      " |  This can be instantiated in several ways:\n",
      " |      csr_matrix(D)\n",
      " |          with a dense matrix or rank-2 ndarray D\n",
      " |  \n",
      " |      csr_matrix(S)\n",
      " |          with another sparse matrix S (equivalent to S.tocsr())\n",
      " |  \n",
      " |      csr_matrix((M, N), [dtype])\n",
      " |          to construct an empty matrix with shape (M, N)\n",
      " |          dtype is optional, defaulting to dtype='d'.\n",
      " |  \n",
      " |      csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
      " |          where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
      " |          relationship ``a[row_ind[k], col_ind[k]] = data[k]``.\n",
      " |  \n",
      " |      csr_matrix((data, indices, indptr), [shape=(M, N)])\n",
      " |          is the standard CSR representation where the column indices for\n",
      " |          row i are stored in ``indices[indptr[i]:indptr[i+1]]`` and their\n",
      " |          corresponding values are stored in ``data[indptr[i]:indptr[i+1]]``.\n",
      " |          If the shape parameter is not supplied, the matrix dimensions\n",
      " |          are inferred from the index arrays.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  dtype : dtype\n",
      " |      Data type of the matrix\n",
      " |  shape : 2-tuple\n",
      " |      Shape of the matrix\n",
      " |  ndim : int\n",
      " |      Number of dimensions (this is always 2)\n",
      " |  nnz\n",
      " |      Number of nonzero elements\n",
      " |  data\n",
      " |      CSR format data array of the matrix\n",
      " |  indices\n",
      " |      CSR format index array of the matrix\n",
      " |  indptr\n",
      " |      CSR format index pointer array of the matrix\n",
      " |  has_sorted_indices\n",
      " |      Whether indices are sorted\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  \n",
      " |  Sparse matrices can be used in arithmetic operations: they support\n",
      " |  addition, subtraction, multiplication, division, and matrix power.\n",
      " |  \n",
      " |  Advantages of the CSR format\n",
      " |    - efficient arithmetic operations CSR + CSR, CSR * CSR, etc.\n",
      " |    - efficient row slicing\n",
      " |    - fast matrix vector products\n",
      " |  \n",
      " |  Disadvantages of the CSR format\n",
      " |    - slow column slicing operations (consider CSC)\n",
      " |    - changes to the sparsity structure are expensive (consider LIL or DOK)\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from scipy.sparse import csr_matrix\n",
      " |  >>> csr_matrix((3, 4), dtype=np.int8).toarray()\n",
      " |  array([[0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0],\n",
      " |         [0, 0, 0, 0]], dtype=int8)\n",
      " |  \n",
      " |  >>> row = np.array([0, 0, 1, 2, 2, 2])\n",
      " |  >>> col = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, (row, col)), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  >>> indptr = np.array([0, 2, 3, 6])\n",
      " |  >>> indices = np.array([0, 2, 2, 0, 1, 2])\n",
      " |  >>> data = np.array([1, 2, 3, 4, 5, 6])\n",
      " |  >>> csr_matrix((data, indices, indptr), shape=(3, 3)).toarray()\n",
      " |  array([[1, 0, 2],\n",
      " |         [0, 0, 3],\n",
      " |         [4, 5, 6]])\n",
      " |  \n",
      " |  As an example of how to construct a CSR matrix incrementally,\n",
      " |  the following snippet builds a term-document matrix from texts:\n",
      " |  \n",
      " |  >>> docs = [[\"hello\", \"world\", \"hello\"], [\"goodbye\", \"cruel\", \"world\"]]\n",
      " |  >>> indptr = [0]\n",
      " |  >>> indices = []\n",
      " |  >>> data = []\n",
      " |  >>> vocabulary = {}\n",
      " |  >>> for d in docs:\n",
      " |  ...     for term in d:\n",
      " |  ...         index = vocabulary.setdefault(term, len(vocabulary))\n",
      " |  ...         indices.append(index)\n",
      " |  ...         data.append(1)\n",
      " |  ...     indptr.append(len(indices))\n",
      " |  ...\n",
      " |  >>> csr_matrix((data, indices, indptr), dtype=int).toarray()\n",
      " |  array([[2, 1, 0, 0],\n",
      " |         [0, 1, 1, 1]])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      csr_matrix\n",
      " |      scipy.sparse.compressed._cs_matrix\n",
      " |      scipy.sparse.data._data_matrix\n",
      " |      scipy.sparse.base.spmatrix\n",
      " |      scipy.sparse.data._minmax_mixin\n",
      " |      scipy.sparse.sputils.IndexMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  getcol(self, i)\n",
      " |      Returns a copy of column i of the matrix, as a (m x 1)\n",
      " |      CSR matrix (column vector).\n",
      " |  \n",
      " |  getrow(self, i)\n",
      " |      Returns a copy of row i of the matrix, as a (1 x n)\n",
      " |      CSR matrix (row vector).\n",
      " |  \n",
      " |  tobsr(self, blocksize=None, copy=True)\n",
      " |  \n",
      " |  tocsc(self)\n",
      " |  \n",
      " |  tocsr(self, copy=False)\n",
      " |  \n",
      " |  tolil(self)\n",
      " |  \n",
      " |  transpose(self, copy=False)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __init__(self, arg1, shape=None, dtype=None, copy=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __radd__(self, other)\n",
      " |  \n",
      " |  __rsub__(self, other)\n",
      " |  \n",
      " |  __setitem__(self, index, x)\n",
      " |  \n",
      " |  __sub__(self, other)\n",
      " |  \n",
      " |  check_format(self, full_check=True)\n",
      " |      check whether the matrix format is valid\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      full_check : bool, optional\n",
      " |          If `True`, rigorous check, O(N) operations. Otherwise\n",
      " |          basic check, O(1) operations (default True).\n",
      " |  \n",
      " |  diagonal(self)\n",
      " |      Returns the main diagonal of the matrix\n",
      " |  \n",
      " |  eliminate_zeros(self)\n",
      " |      Remove zero entries from the matrix\n",
      " |      \n",
      " |      This is an *in place* operation\n",
      " |  \n",
      " |  getnnz(self, axis=None)\n",
      " |      Get the count of explicitly-stored values (nonzeros)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None, 0, 1}, optional\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |  \n",
      " |  maximum(self, other)\n",
      " |  \n",
      " |  minimum(self, other)\n",
      " |  \n",
      " |  multiply(self, other)\n",
      " |      Point-wise multiplication by another matrix, vector, or\n",
      " |      scalar.\n",
      " |  \n",
      " |  prune(self)\n",
      " |      Remove empty space after all non-zero elements.\n",
      " |  \n",
      " |  sort_indices(self)\n",
      " |      Sort the indices of this matrix *in place*\n",
      " |  \n",
      " |  sorted_indices(self)\n",
      " |      Return a copy of this matrix with sorted indices\n",
      " |  \n",
      " |  sum(self, axis=None)\n",
      " |      Sum the matrix over the given axis.  If the axis is None, sum\n",
      " |      over both rows and columns, returning a scalar.\n",
      " |  \n",
      " |  sum_duplicates(self)\n",
      " |      Eliminate duplicate matrix entries by adding them together\n",
      " |      \n",
      " |      The is an *in place* operation\n",
      " |  \n",
      " |  toarray(self, order=None, out=None)\n",
      " |      See the docstring for `spmatrix.toarray`.\n",
      " |  \n",
      " |  tocoo(self, copy=True)\n",
      " |      Return a COOrdinate representation of this matrix\n",
      " |      \n",
      " |      When copy=False the index and data arrays are not copied.\n",
      " |  \n",
      " |  todia(self)\n",
      " |  \n",
      " |  todok(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  has_canonical_format\n",
      " |      Determine whether the matrix has sorted indices and no duplicates\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the above applies\n",
      " |          - False: otherwise\n",
      " |      \n",
      " |      has_canonical_format implies has_sorted_indices, so if the latter flag\n",
      " |      is False, so will the former be; if the former is found True, the\n",
      " |      latter flag is also set.\n",
      " |  \n",
      " |  has_sorted_indices\n",
      " |      Determine whether the matrix has sorted indices\n",
      " |      \n",
      " |      Returns\n",
      " |          - True: if the indices of the matrix are in sorted order\n",
      " |          - False: otherwise\n",
      " |  \n",
      " |  nnz\n",
      " |      Get the count of explicitly-stored values (nonzeros)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {None, 0, 1}, optional\n",
      " |          Select between the number of values across the whole matrix, in\n",
      " |          each column, or in each row.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse.compressed._cs_matrix:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __imul__(self, other)\n",
      " |  \n",
      " |  __itruediv__(self, other)\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  arcsin(self)\n",
      " |      Element-wise arcsin.\n",
      " |      \n",
      " |      See numpy.arcsin for more information.\n",
      " |  \n",
      " |  arcsinh(self)\n",
      " |      Element-wise arcsinh.\n",
      " |      \n",
      " |      See numpy.arcsinh for more information.\n",
      " |  \n",
      " |  arctan(self)\n",
      " |      Element-wise arctan.\n",
      " |      \n",
      " |      See numpy.arctan for more information.\n",
      " |  \n",
      " |  arctanh(self)\n",
      " |      Element-wise arctanh.\n",
      " |      \n",
      " |      See numpy.arctanh for more information.\n",
      " |  \n",
      " |  astype(self, t)\n",
      " |  \n",
      " |  ceil(self)\n",
      " |      Element-wise ceil.\n",
      " |      \n",
      " |      See numpy.ceil for more information.\n",
      " |  \n",
      " |  conj(self)\n",
      " |  \n",
      " |  copy(self)\n",
      " |  \n",
      " |  deg2rad(self)\n",
      " |      Element-wise deg2rad.\n",
      " |      \n",
      " |      See numpy.deg2rad for more information.\n",
      " |  \n",
      " |  expm1(self)\n",
      " |      Element-wise expm1.\n",
      " |      \n",
      " |      See numpy.expm1 for more information.\n",
      " |  \n",
      " |  floor(self)\n",
      " |      Element-wise floor.\n",
      " |      \n",
      " |      See numpy.floor for more information.\n",
      " |  \n",
      " |  log1p(self)\n",
      " |      Element-wise log1p.\n",
      " |      \n",
      " |      See numpy.log1p for more information.\n",
      " |  \n",
      " |  power(self, n, dtype=None)\n",
      " |      This function performs element-wise power.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n : n is a scalar\n",
      " |      \n",
      " |      dtype : If dtype is not specified, the current dtype will be preserved.\n",
      " |  \n",
      " |  rad2deg(self)\n",
      " |      Element-wise rad2deg.\n",
      " |      \n",
      " |      See numpy.rad2deg for more information.\n",
      " |  \n",
      " |  rint(self)\n",
      " |      Element-wise rint.\n",
      " |      \n",
      " |      See numpy.rint for more information.\n",
      " |  \n",
      " |  sign(self)\n",
      " |      Element-wise sign.\n",
      " |      \n",
      " |      See numpy.sign for more information.\n",
      " |  \n",
      " |  sin(self)\n",
      " |      Element-wise sin.\n",
      " |      \n",
      " |      See numpy.sin for more information.\n",
      " |  \n",
      " |  sinh(self)\n",
      " |      Element-wise sinh.\n",
      " |      \n",
      " |      See numpy.sinh for more information.\n",
      " |  \n",
      " |  sqrt(self)\n",
      " |      Element-wise sqrt.\n",
      " |      \n",
      " |      See numpy.sqrt for more information.\n",
      " |  \n",
      " |  tan(self)\n",
      " |      Element-wise tan.\n",
      " |      \n",
      " |      See numpy.tan for more information.\n",
      " |  \n",
      " |  tanh(self)\n",
      " |      Element-wise tanh.\n",
      " |      \n",
      " |      See numpy.tanh for more information.\n",
      " |  \n",
      " |  trunc(self)\n",
      " |      Element-wise trunc.\n",
      " |      \n",
      " |      See numpy.trunc for more information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.data._data_matrix:\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __div__(self, other)\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __iadd__(self, other)\n",
      " |  \n",
      " |  __idiv__(self, other)\n",
      " |  \n",
      " |  __isub__(self, other)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      # What should len(sparse) return? For consistency with dense matrices,\n",
      " |      # perhaps it should be the number of rows?  But for some uses the number of\n",
      " |      # non-zeros is more important.  For now, raise an exception!\n",
      " |  \n",
      " |  __matmul__(self, other)\n",
      " |  \n",
      " |  __mul__(self, other)\n",
      " |      interpret other and call one of the following\n",
      " |      \n",
      " |      self._mul_scalar()\n",
      " |      self._mul_vector()\n",
      " |      self._mul_multivector()\n",
      " |      self._mul_sparse_matrix()\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __numpy_ufunc__(self, func, method, pos, inputs, **kwargs)\n",
      " |      Method for compatibility with NumPy's ufuncs and dot\n",
      " |      functions.\n",
      " |  \n",
      " |  __pow__(self, other)\n",
      " |  \n",
      " |  __rdiv__(self, other)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rmatmul__(self, other)\n",
      " |  \n",
      " |  __rmul__(self, other)\n",
      " |  \n",
      " |  __rtruediv__(self, other)\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __truediv__(self, other)\n",
      " |  \n",
      " |  asformat(self, format)\n",
      " |      Return this matrix in a given sparse format\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      format : {string, None}\n",
      " |          desired sparse matrix format\n",
      " |              - None for no format conversion\n",
      " |              - \"csr\" for csr_matrix format\n",
      " |              - \"csc\" for csc_matrix format\n",
      " |              - \"lil\" for lil_matrix format\n",
      " |              - \"dok\" for dok_matrix format and so on\n",
      " |  \n",
      " |  asfptype(self)\n",
      " |      Upcast matrix to a floating point format (if necessary)\n",
      " |  \n",
      " |  conjugate(self)\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Ordinary dot product\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import numpy as np\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1, 2, 0], [0, 0, 3], [4, 0, 5]])\n",
      " |      >>> v = np.array([1, 0, -1])\n",
      " |      >>> A.dot(v)\n",
      " |      array([ 1, -3, -1], dtype=int64)\n",
      " |  \n",
      " |  getH(self)\n",
      " |      # Renamed conjtranspose() -> getH() for compatibility with dense matrices\n",
      " |  \n",
      " |  get_shape(self)\n",
      " |  \n",
      " |  getformat(self)\n",
      " |  \n",
      " |  getmaxprint(self)\n",
      " |  \n",
      " |  mean(self, axis=None)\n",
      " |      Average the matrix over the given axis.  If the axis is None,\n",
      " |      average over both rows and columns, returning a scalar.\n",
      " |  \n",
      " |  nonzero(self)\n",
      " |      nonzero indices\n",
      " |      \n",
      " |      Returns a tuple of arrays (row,col) containing the indices\n",
      " |      of the non-zero elements of the matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from scipy.sparse import csr_matrix\n",
      " |      >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])\n",
      " |      >>> A.nonzero()\n",
      " |      (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))\n",
      " |  \n",
      " |  reshape(self, shape)\n",
      " |  \n",
      " |  set_shape(self, shape)\n",
      " |  \n",
      " |  setdiag(self, values, k=0)\n",
      " |      Set diagonal or off-diagonal elements of the array.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : array_like\n",
      " |          New values of the diagonal elements.\n",
      " |      \n",
      " |          Values may have any length.  If the diagonal is longer than values,\n",
      " |          then the remaining diagonal entries will not be set.  If values if\n",
      " |          longer than the diagonal, then the remaining values are ignored.\n",
      " |      \n",
      " |          If a scalar value is given, all of the diagonal is set to it.\n",
      " |      \n",
      " |      k : int, optional\n",
      " |          Which off-diagonal to set, corresponding to elements a[i,i+k].\n",
      " |          Default: 0 (the main diagonal).\n",
      " |  \n",
      " |  todense(self, order=None, out=None)\n",
      " |      Return a dense matrix representation of this matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : {'C', 'F'}, optional\n",
      " |          Whether to store multi-dimensional data in C (row-major)\n",
      " |          or Fortran (column-major) order in memory. The default\n",
      " |          is 'None', indicating the NumPy default of C-ordered.\n",
      " |          Cannot be specified in conjunction with the `out`\n",
      " |          argument.\n",
      " |      \n",
      " |      out : ndarray, 2-dimensional, optional\n",
      " |          If specified, uses this array (or `numpy.matrix`) as the\n",
      " |          output buffer instead of allocating a new array to\n",
      " |          return. The provided array must have the same shape and\n",
      " |          dtype as the sparse matrix on which you are calling the\n",
      " |          method.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr : numpy.matrix, 2-dimensional\n",
      " |          A NumPy matrix object with the same shape and containing\n",
      " |          the same data represented by the sparse matrix, with the\n",
      " |          requested memory order. If `out` was passed and was an\n",
      " |          array (rather than a `numpy.matrix`), it will be filled\n",
      " |          with the appropriate values and returned wrapped in a\n",
      " |          `numpy.matrix` object that shares the same memory.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from scipy.sparse.base.spmatrix:\n",
      " |  \n",
      " |  __array_priority__ = 10.1\n",
      " |  \n",
      " |  ndim = 2\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from scipy.sparse.data._minmax_mixin:\n",
      " |  \n",
      " |  max(self, axis=None)\n",
      " |      Maximum of the elements of this matrix.\n",
      " |      \n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amax : self.dtype\n",
      " |          Maximum element.\n",
      " |  \n",
      " |  min(self, axis=None)\n",
      " |      Minimum of the elements of this matrix.\n",
      " |      \n",
      " |      This takes all elements into account, not just the non-zero ones.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      amin : self.dtype\n",
      " |          Minimum element.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x32801 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 35 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How is tweet 201 stored?\n",
    "X[201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method nonzero in module scipy.sparse.base:\n",
      "\n",
      "nonzero() method of scipy.sparse.csr.csr_matrix instance\n",
      "    nonzero indices\n",
      "    \n",
      "    Returns a tuple of arrays (row,col) containing the indices\n",
      "    of the non-zero elements of the matrix.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy.sparse import csr_matrix\n",
      "    >>> A = csr_matrix([[1,2,0],[0,0,3],[4,0,5]])\n",
      "    >>> A.nonzero()\n",
      "    (array([0, 0, 1, 2, 2]), array([0, 1, 2, 0, 2]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(X[201].nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31,   80,  147,  150,  164,  436,  682,  690,  726,  960, 1156,\n",
       "       1173, 2511, 2516, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703,\n",
       "       2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714,\n",
       "       2715, 2716], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-zero indices of terms used in tweet 200.\n",
    "X[201].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  5.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term counts for tweet 200.\n",
    "X[201].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=of\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# What word does each term index correspond to?\n",
    "# Convert term->index dict into index->term dict\n",
    "index2term = {i: t for t, i in vocabulary.items()}\n",
    "print(index2term[80])\n",
    "print(X[201, 80])\n",
    "# So, the term \"d=of\" (index 80) appears in user 201's tweet five times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=the\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# d=the appears one time.\n",
    "print(index2term[31])\n",
    "print(X[201, 31])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do CSR matrices access row values?\n",
    "\n",
    "Recall:\n",
    "\n",
    "CSR Matrix is an object with three attributes: \n",
    "- **val:** $\\{1,2,1,1\\}$  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *list of all non-zero values*  \n",
    "- **col_ind:** $\\{0,3,0,1\\}$ &nbsp; *column index for each non-zero value* (e.g., first non-zero value (1) is in column 0) \n",
    "- **row_ptr (ind_ptr):** $\\{0,1,2\\}$ &nbsp;&nbsp;&nbsp; *index into **col_ind** where each row starts* (e.g., tweet3, term1 corresponds to col_ind[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200, 300, 400])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall: numpy array slices.\n",
    "import numpy as np\n",
    "a = np.array([0, 100, 200, 300, 400, 500])\n",
    "a[2:5]  # get elements at positions 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 200 starts at col_ind= 4104\n",
      "tweet 201 starts at col_ind= 4139\n",
      "so, the columns that are non-zero for tweet 201 are:\n",
      "[  31   80  147  150  164  436  682  690  726  960 1156 1173 2511 2516 2696\n",
      " 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711\n",
      " 2712 2713 2714 2715 2716]\n",
      "and the data associated with those cells are:\n",
      "[ 1.  5.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#where the column indices for row i are stored in indices[indptr[i]:indptr[i+1]] \n",
    "#and their corresponding values are stored in data[indptr[i]:indptr[i+1]]\n",
    "#so the X.indptr[r] is the number of elements stored before r'th tweet begins to store\n",
    "print('tweet 200 starts at col_ind=', X.indptr[201])\n",
    "print('tweet 201 starts at col_ind=', X.indptr[202])\n",
    "print('so, the columns that are non-zero for tweet 201 are:')\n",
    "print(X.indices[X.indptr[201]:X.indptr[202]])\n",
    "print('and the data associated with those cells are:')\n",
    "print(X.data[X.indptr[201]:X.indptr[202]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet 0:\n",
      "   (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (0, 2)\t1.0\n",
      "  (0, 3)\t1.0\n",
      "  (0, 4)\t1.0\n",
      "  (0, 5)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 7)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 10)\t1.0\n",
      "  (0, 11)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 14)\t1.0\n",
      "  (0, 15)\t1.0\n",
      "  (0, 16)\t1.0\n",
      "  (0, 17)\t1.0\n",
      "  (0, 18)\t1.0\n",
      "  (0, 19)\t1.0\n",
      "  (0, 20)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 22)\t1.0\n",
      "  (0, 23)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 25)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 27)\t1.0\n",
      "  (0, 28)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (0, 31)\t1.0\n",
      "  (0, 32)\t1.0\n",
      "  (0, 33)\t1.0\n",
      "  (0, 34)\t1.0\n",
      "  (0, 35)\t1.0 \n",
      "\n",
      "tweet 1:\n",
      "   (0, 36)\t1.0\n",
      "  (0, 37)\t1.0\n",
      "  (0, 38)\t1.0\n",
      "  (0, 39)\t1.0\n",
      "  (0, 40)\t2.0\n",
      "  (0, 41)\t1.0\n",
      "  (0, 42)\t1.0\n",
      "  (0, 43)\t2.0\n",
      "  (0, 44)\t1.0\n",
      "  (0, 45)\t1.0\n",
      "  (0, 46)\t1.0\n",
      "  (0, 47)\t1.0\n",
      "  (0, 48)\t1.0\n",
      "  (0, 49)\t1.0\n",
      "  (0, 50)\t1.0\n",
      "  (0, 51)\t1.0\n",
      "  (0, 52)\t1.0\n",
      "  (0, 53)\t1.0\n",
      "  (0, 54)\t1.0\n",
      "  (0, 55)\t1.0\n",
      "  (0, 56)\t1.0\n",
      "  (0, 57)\t1.0\n",
      "  (0, 58)\t1.0\n",
      "  (0, 59)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 61)\t1.0 \n",
      "\n",
      "tweet 2:\n",
      "   (0, 8)\t1.0\n",
      "  (0, 9)\t1.0\n",
      "  (0, 62)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 64)\t1.0\n",
      "  (0, 65)\t1.0\n",
      "  (0, 66)\t1.0\n",
      "  (0, 67)\t1.0\n",
      "  (0, 68)\t2.0\n",
      "  (0, 69)\t1.0\n",
      "  (0, 70)\t1.0\n",
      "  (0, 71)\t1.0\n",
      "  (0, 72)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 74)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 76)\t1.0\n",
      "  (0, 77)\t1.0\n",
      "  (0, 78)\t1.0\n",
      "  (0, 79)\t1.0\n",
      "  (0, 80)\t1.0\n",
      "  (0, 81)\t1.0\n",
      "  (0, 82)\t1.0\n",
      "  (0, 83)\t1.0\n",
      "  (0, 84)\t1.0\n",
      "  (0, 85)\t1.0\n",
      "  (0, 86)\t1.0\n",
      "  (0, 87)\t1.0\n",
      "  (0, 88)\t1.0\n",
      "  (0, 89)\t1.0\n",
      "  (0, 90)\t1.0\n",
      "  (0, 91)\t1.0\n",
      "  (0, 92)\t1.0\n",
      "  (0, 93)\t1.0\n",
      "  (0, 94)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print('tweet 0:\\n', X[0], '\\n')\n",
    "print('tweet 1:\\n', X[1], '\\n')\n",
    "print('tweet 2:\\n', X[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Efficient matrix vector product:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X * beta for tweet 201= 39.0\n",
      "which is the same as the sum 39.0, since beta=[1...1]\n"
     ]
    }
   ],
   "source": [
    "# Compute z = X * \\beta, where X is a CSR matrix.\n",
    "import numpy as np\n",
    "beta = np.ones(len(vocabulary))  # assume Beta = vector of 1's\n",
    "z = np.zeros(len(tweets))\n",
    "for i in range(len(tweets)):  # for each row.\n",
    "    for j in range(X.indptr[i], X.indptr[i+1]): # for each col.\n",
    "        colidx = X.indices[j]\n",
    "        z[i] += beta[colidx] * X.data[j]\n",
    "print('X * beta for tweet 201=', z[201])\n",
    "print('which is the same as the sum %.1f, since beta=[1...1]' % X[201].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.) Create a list of gender labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender labels: Counter({0: 2582, 1: 2418})\n"
     ]
    }
   ],
   "source": [
    "# y is a 1d numpy array of gender labels.\n",
    "# Let 1=Female, 0=Male.\n",
    "import numpy as np\n",
    "\n",
    "def get_gender(tweet, male_names, female_names):\n",
    "    name = get_first_name(tweet)\n",
    "    if name in female_names:\n",
    "        return 1\n",
    "    elif name in male_names:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "y = np.array([get_gender(t, male_names, female_names) for t in tweets])\n",
    "print('gender labels:', Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.) Fit a Logistic Regression classifier to predict gender from profile/tweet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dan/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do 5-fold cross-validation\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def do_cross_val(X, y, nfolds):\n",
    "    \"\"\" Compute average cross-validation acccuracy.\"\"\"\n",
    "    cv = KFold(len(y), nfolds)\n",
    "    accuracies = []\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X[train_idx], y[train_idx])\n",
    "        predicted = clf.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predicted)\n",
    "        accuracies.append(acc)\n",
    "    avg = np.mean(accuracies)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accuracy 0.6842\n"
     ]
    }
   ],
   "source": [
    "print('avg accuracy', do_cross_val(X, y, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR TIME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6158271009917371"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model with CSR much, much faster than with LIL.\n",
    "from timeit import timeit\n",
    "print('CSR TIME')\n",
    "timeit(\"do_cross_val(X.tocsr(), y, 2)\", number=5,\n",
    "       setup=\"from __main__ import do_cross_val, X, y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIL TIME\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "252.9111922950251"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('LIL TIME')\n",
    "timeit(\"do_cross_val(X.tolil(), y, 2)\", number=5,\n",
    "       setup=\"from __main__ import do_cross_val, X, y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How does tokenization affect accuracy?\n",
    "# Collapse urls and mentions; ignore description prefix.\n",
    "def run_all(tweets, use_descr=True, lowercase=True,\n",
    "            keep_punctuation=True, descr_prefix=None,\n",
    "            collapse_urls=True, collapse_mentions=True):\n",
    "    \n",
    "    tokens_list = [tweet2tokens(t, use_descr, lowercase,\n",
    "                            keep_punctuation, descr_prefix,\n",
    "                            collapse_urls, collapse_mentions)\n",
    "                  for t in tweets]\n",
    "    vocabulary = make_vocabulary(tokens_list)\n",
    "    X = make_feature_matrix(tokens_list, vocabulary)\n",
    "    acc = do_cross_val(X, y, 5)\n",
    "    print('acc=', acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "27237 unique terms in vocabulary\n",
      "acc= 0.6826\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "30685 unique terms in vocabulary\n",
      "acc= 0.6848\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "29353 unique terms in vocabulary\n",
      "acc= 0.6832\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "32801 unique terms in vocabulary\n",
      "acc= 0.6842\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "24001 unique terms in vocabulary\n",
      "acc= 0.6834\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "27416 unique terms in vocabulary\n",
      "acc= 0.6906\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "26118 unique terms in vocabulary\n",
      "acc= 0.6866\n",
      "use_descr=True\tlower=True\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "29533 unique terms in vocabulary\n",
      "acc= 0.6888\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "19261 unique terms in vocabulary\n",
      "acc= 0.6846\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "22596 unique terms in vocabulary\n",
      "acc= 0.6884\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "21395 unique terms in vocabulary\n",
      "acc= 0.6868\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "24722 unique terms in vocabulary\n",
      "acc= 0.6892\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "15868 unique terms in vocabulary\n",
      "acc= 0.6858\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "19121 unique terms in vocabulary\n",
      "acc= 0.6862\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "17995 unique terms in vocabulary\n",
      "acc= 0.6892\n",
      "use_descr=True\tlower=True\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "21242 unique terms in vocabulary\n",
      "acc= 0.6898\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "30761 unique terms in vocabulary\n",
      "acc= 0.6834\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "34226 unique terms in vocabulary\n",
      "acc= 0.684\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "32877 unique terms in vocabulary\n",
      "acc= 0.6846\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "36342 unique terms in vocabulary\n",
      "acc= 0.6818\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "27407 unique terms in vocabulary\n",
      "acc= 0.6892\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "30850 unique terms in vocabulary\n",
      "acc= 0.689\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "29524 unique terms in vocabulary\n",
      "acc= 0.6878\n",
      "use_descr=True\tlower=False\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "32967 unique terms in vocabulary\n",
      "acc= 0.6898\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "23148 unique terms in vocabulary\n",
      "acc= 0.6914\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "26553 unique terms in vocabulary\n",
      "acc= 0.688\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "25300 unique terms in vocabulary\n",
      "acc= 0.6896\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "28700 unique terms in vocabulary\n",
      "acc= 0.689\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "19536 unique terms in vocabulary\n",
      "acc= 0.6918\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "22875 unique terms in vocabulary\n",
      "acc= 0.691\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "21679 unique terms in vocabulary\n",
      "acc= 0.6896\n",
      "use_descr=True\tlower=False\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "25015 unique terms in vocabulary\n",
      "acc= 0.6918\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "13120 unique terms in vocabulary\n",
      "acc= 0.5752\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "15684 unique terms in vocabulary\n",
      "acc= 0.5874\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "15053 unique terms in vocabulary\n",
      "acc= 0.5788\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "17617 unique terms in vocabulary\n",
      "acc= 0.5904\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "13120 unique terms in vocabulary\n",
      "acc= 0.5752\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "15684 unique terms in vocabulary\n",
      "acc= 0.5874\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "15053 unique terms in vocabulary\n",
      "acc= 0.5788\n",
      "use_descr=False\tlower=True\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "17617 unique terms in vocabulary\n",
      "acc= 0.5904\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "9228 unique terms in vocabulary\n",
      "acc= 0.5816\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "11728 unique terms in vocabulary\n",
      "acc= 0.5884\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "11164 unique terms in vocabulary\n",
      "acc= 0.5798\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "13664 unique terms in vocabulary\n",
      "acc= 0.5884\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "9228 unique terms in vocabulary\n",
      "acc= 0.5816\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "11728 unique terms in vocabulary\n",
      "acc= 0.5884\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "11164 unique terms in vocabulary\n",
      "acc= 0.5798\n",
      "use_descr=False\tlower=True\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "13664 unique terms in vocabulary\n",
      "acc= 0.5884\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=True\n",
      "14742 unique terms in vocabulary\n",
      "acc= 0.5854\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=True\tmention=False\n",
      "17314 unique terms in vocabulary\n",
      "acc= 0.5928\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=True\n",
      "16675 unique terms in vocabulary\n",
      "acc= 0.5832\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=d=\turl=False\tmention=False\n",
      "19247 unique terms in vocabulary\n",
      "acc= 0.5938\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=True\tmention=True\n",
      "14742 unique terms in vocabulary\n",
      "acc= 0.5854\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=True\tmention=False\n",
      "17314 unique terms in vocabulary\n",
      "acc= 0.5928\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=False\tmention=True\n",
      "16675 unique terms in vocabulary\n",
      "acc= 0.5832\n",
      "use_descr=False\tlower=False\tpunct=True\tprefix=\turl=False\tmention=False\n",
      "19247 unique terms in vocabulary\n",
      "acc= 0.5938\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=True\n",
      "11023 unique terms in vocabulary\n",
      "acc= 0.584\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=True\tmention=False\n",
      "13550 unique terms in vocabulary\n",
      "acc= 0.5928\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=True\n",
      "12959 unique terms in vocabulary\n",
      "acc= 0.587\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=d=\turl=False\tmention=False\n",
      "15486 unique terms in vocabulary\n",
      "acc= 0.5952\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=True\tmention=True\n",
      "11023 unique terms in vocabulary\n",
      "acc= 0.584\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=True\tmention=False\n",
      "13550 unique terms in vocabulary\n",
      "acc= 0.5928\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=False\tmention=True\n",
      "12959 unique terms in vocabulary\n",
      "acc= 0.587\n",
      "use_descr=False\tlower=False\tpunct=False\tprefix=\turl=False\tmention=False\n",
      "15486 unique terms in vocabulary\n",
      "acc= 0.5952\n"
     ]
    }
   ],
   "source": [
    "argnames = ['use_descr', 'lower', 'punct', 'prefix', 'url', 'mention']\n",
    "option_iter = product(use_descr_opts, lowercase_opts,\n",
    "                       keep_punctuation_opts,\n",
    "                       descr_prefix_opts, url_opts,\n",
    "                       mention_opts)\n",
    "results = []\n",
    "for options in option_iter:\n",
    "    option_str = '\\t'.join('%s=%s' % (name, opt) for name, opt in zip(argnames, options))\n",
    "    print(option_str)\n",
    "    acc = run_all(tweets, *options)\n",
    "    results.append((acc, options))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6918 use_descr=True  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "0.6918 use_descr=True  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "0.6914 use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "0.6910 use_descr=True  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "0.6906 use_descr=True  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "0.6898 use_descr=True  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "0.6898 use_descr=True  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "0.6896 use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "0.6896 use_descr=True  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "0.6892 use_descr=True  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "0.6892 use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "0.6892 use_descr=True  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "0.6890 use_descr=True  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "0.6890 use_descr=True  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "0.6888 use_descr=True  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "0.6884 use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "0.6880 use_descr=True  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "0.6878 use_descr=True  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "0.6868 use_descr=True  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "0.6866 use_descr=True  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "0.6862 use_descr=True  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "0.6858 use_descr=True  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "0.6848 use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "0.6846 use_descr=True  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "0.6846 use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "0.6842 use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "0.6840 use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "0.6834 use_descr=True  lower=True  punct=True  prefix=  url=True  mention=True\n",
      "0.6834 use_descr=True  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "0.6832 use_descr=True  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "0.6826 use_descr=True  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "0.6818 use_descr=True  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "0.5952 use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=False\n",
      "0.5952 use_descr=False  lower=False  punct=False  prefix=  url=False  mention=False\n",
      "0.5938 use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=False\n",
      "0.5938 use_descr=False  lower=False  punct=True  prefix=  url=False  mention=False\n",
      "0.5928 use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=False\n",
      "0.5928 use_descr=False  lower=False  punct=True  prefix=  url=True  mention=False\n",
      "0.5928 use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=False\n",
      "0.5928 use_descr=False  lower=False  punct=False  prefix=  url=True  mention=False\n",
      "0.5904 use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=False\n",
      "0.5904 use_descr=False  lower=True  punct=True  prefix=  url=False  mention=False\n",
      "0.5884 use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=False\n",
      "0.5884 use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=False\n",
      "0.5884 use_descr=False  lower=True  punct=False  prefix=  url=True  mention=False\n",
      "0.5884 use_descr=False  lower=True  punct=False  prefix=  url=False  mention=False\n",
      "0.5874 use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=False\n",
      "0.5874 use_descr=False  lower=True  punct=True  prefix=  url=True  mention=False\n",
      "0.5870 use_descr=False  lower=False  punct=False  prefix=d=  url=False  mention=True\n",
      "0.5870 use_descr=False  lower=False  punct=False  prefix=  url=False  mention=True\n",
      "0.5854 use_descr=False  lower=False  punct=True  prefix=d=  url=True  mention=True\n",
      "0.5854 use_descr=False  lower=False  punct=True  prefix=  url=True  mention=True\n",
      "0.5840 use_descr=False  lower=False  punct=False  prefix=d=  url=True  mention=True\n",
      "0.5840 use_descr=False  lower=False  punct=False  prefix=  url=True  mention=True\n",
      "0.5832 use_descr=False  lower=False  punct=True  prefix=d=  url=False  mention=True\n",
      "0.5832 use_descr=False  lower=False  punct=True  prefix=  url=False  mention=True\n",
      "0.5816 use_descr=False  lower=True  punct=False  prefix=d=  url=True  mention=True\n",
      "0.5816 use_descr=False  lower=True  punct=False  prefix=  url=True  mention=True\n",
      "0.5798 use_descr=False  lower=True  punct=False  prefix=d=  url=False  mention=True\n",
      "0.5798 use_descr=False  lower=True  punct=False  prefix=  url=False  mention=True\n",
      "0.5788 use_descr=False  lower=True  punct=True  prefix=d=  url=False  mention=True\n",
      "0.5788 use_descr=False  lower=True  punct=True  prefix=  url=False  mention=True\n",
      "0.5752 use_descr=False  lower=True  punct=True  prefix=d=  url=True  mention=True\n",
      "0.5752 use_descr=False  lower=True  punct=True  prefix=  url=True  mention=True\n"
     ]
    }
   ],
   "source": [
    "for r in sorted(results, reverse=True):\n",
    "    print('%.4f' % r[0], '  '.join('%s=%s' % (name, opt) for name, opt in zip(argnames, r[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "- Which ones do we get wrong?\n",
    "- Are there obvious reasons?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
